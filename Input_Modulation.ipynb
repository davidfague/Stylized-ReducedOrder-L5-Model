{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Input Modulation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7DgF2K12dZtrUD3GzAPhS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidfague/Stylized-ReducedOrder-L5-Model/blob/main/Input_Modulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Functions used for creating inputs"
      ],
      "metadata": {
        "id": "_krmUid8j8u-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "build_network.py\n",
        "https://github.com/latimerb/L5NeuronSimulation/blob/dea91c052102bb4c2a58b860ebed88b3af4a24bc/L5NeuronSimulation/FullSimulation/build_network.py#L626"
      ],
      "metadata": {
        "id": "dcxjpLvli_xW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qi0f-3jgigwU"
      },
      "outputs": [],
      "source": [
        "        def _make_rasters(self):\n",
        "                \"\"\"Generates excitatory and inhibitory input rasters\n",
        "                \"\"\"    \n",
        "                np.random.seed(self.seed + 9)\n",
        "                self._gen_exc_spikes('exc_stim_spikes.h5')\n",
        "\n",
        "                inh_frs = self.params[\"inh_frs\"]\n",
        "\n",
        "                #Makes perisomatic inhibitory raster.\n",
        "                np.random.seed(self.seed + 10)\n",
        "                self._gen_inh_spikes(self.n_soma_inh + self.n_prox_dend_inh, \n",
        "                                     inh_frs[\"proximal\"][\"m\"], \n",
        "                                     inh_frs[\"proximal\"][\"s\"], \n",
        "                                     inh_frs[\"proximal\"][\"rhythmicity\"],\n",
        "                                     \"prox_inh_stim\", \n",
        "                                     'prox_inh_stim_spikes.h5')\n",
        "                \n",
        "                #Makes dendritic inhibitory raster.\n",
        "                np.random.seed(self.seed + 11)\n",
        "                self._gen_inh_spikes(self.n_apic_inh + self.n_dend_inh, \n",
        "                                     inh_frs[\"distal\"][\"m\"], \n",
        "                                     inh_frs[\"distal\"][\"s\"],\n",
        "                                     inh_frs[\"distal\"][\"rhythmicity\"],\n",
        "                                     \"dist_inh_stim\", \n",
        "                                     'dist_inh_stim_spikes.h5')\n",
        "\n",
        "\n",
        "        #Generates the spike raster for a given group.\n",
        "        #The group has the same noise.\n",
        "        def _gen_group_spikes(writer, group, seconds, start_time, dist):\n",
        "                \"\"\"Generates and writes to a h5 file the given functional group's spike trains\n",
        "                Parameters\n",
        "                ----------\n",
        "                writer : SonataWriter\n",
        "                    how the spike trains are saved\n",
        "                group : FunctionalGroup\n",
        "                    the functional group that the spike trains are being made for\n",
        "                seconds : float\n",
        "                    length of the spike trains in seconds\n",
        "                start_time : float\n",
        "                    what time (ms) the spike trains should start at\n",
        "                dist : func\n",
        "                    function for random distribution used for an individual cell's firing rate\n",
        "                \"\"\"                \n",
        "                z = make_noise(num_samples=(int(seconds*1000))-1,num_traces=1)#generates the noise trace common to each cell in the functional group.\n",
        "                make_save_spikes(writer, True, dist(size=group.n_cells), numUnits=group.n_cells,\n",
        "                        rateProf=np.tile(z[0,:],(group.n_cells,1)),start_id=group.start_id,\n",
        "                        start_time=start_time)\n",
        "\n",
        "        #Creates the excitatory input raster from the functional groups.\n",
        "        def _gen_exc_spikes(self, fname):\n",
        "                \"\"\"Generates the excitatory input raster for all of the functional groups\n",
        "                Parameters\n",
        "                ----------\n",
        "                fname : str\n",
        "                    name of the file to save the rasters in (.h5)\n",
        "                \"\"\"    \n",
        "                #distribution used for generating excitatory firing rates.    \n",
        "                levy_dist = partial(st.levy_stable.rvs, alpha=1.37, beta=-1.00, loc=0.92, scale=0.44, size=1)\n",
        "\n",
        "                length = self.params[\"time\"][\"stop\"] - self.params[\"time\"][\"start\"]\n",
        "                buffer = self.params[\"time\"][\"start\"]\n",
        "\n",
        "                writer = SonataWriter(fname, [\"spikes\", \"exc_stim\"], [\"timestamps\", \"node_ids\"], [np.float, np.int])\n",
        "\n",
        "                for group in (self.dend_groups + self.apic_groups):\n",
        "                        SimulationBuilder._gen_group_spikes(writer, group, length, buffer*1000, levy_dist)\n",
        "                \n",
        "\n",
        "        #Blocks off the bottom of a normal distribution.\n",
        "        def _norm_rvs(mean, std):\n",
        "                \"\"\"Generates a random float from a normal distribution with a near zero minimum\n",
        "                Parameters\n",
        "                ----------\n",
        "                mean : float\n",
        "                    mean of the distribution\n",
        "                std : float\n",
        "                    standard deviation of the distribution\n",
        "                Returns\n",
        "                -------\n",
        "                float\n",
        "                    random float\n",
        "                \"\"\"                \n",
        "                return max(st.norm.rvs(loc=mean, scale=std, size=1), 0.001)\n",
        "\n",
        "        # #Makes a spike raster with each cell having its own noise trace.\n",
        "        # def gen_inh_spikes(n_cells, mean_fr, std_fr, key, file, times):\n",
        "        #         # node_ids = []\n",
        "        #         # timestamps = []\n",
        "\n",
        "        #         length = times[1] - times[0]\n",
        "        #         buffer = times[0]\n",
        "\n",
        "        #         writer = SonataWriter(file, [\"spikes\", key], [\"timestamps\", \"node_ids\"], [np.float, np.int])\n",
        "\n",
        "        #         z = make_noise(num_samples=(int(length*1000))-1,num_traces=1)\n",
        "        #         make_save_spikes(writer, False, partial(positive_normal, mean=mean_fr, std=std_fr), numUnits=n_cells,rateProf=z[0,:],start_time=buffer*1000)\n",
        "\n",
        "        #Creates a spike raster with each cell having the same noise coming from the a shifted average of excitation.\n",
        "        def _gen_inh_spikes(self, n_cells, mean_fr, std_fr, rhythmic_dict, key, fname):\n",
        "                \"\"\"Generates a spike raster with each train having the noise trace from\n",
        "                averaging excitation. Distributes firing rates normally.\n",
        "                Parameters\n",
        "                ----------\n",
        "                n_cells : int\n",
        "                    number of spike trains\n",
        "                mean_fr : float\n",
        "                    mean firing rate\n",
        "                std_fr : float\n",
        "                    standard deviation of the firing rate\n",
        "                rhythmic_dict : dict\n",
        "                    dictionary with keys f - frequency, mod - depth of modulation\n",
        "                key : str\n",
        "                    name of the second group in the h5 file\n",
        "                fname : str\n",
        "                    name of file to save the raster to\n",
        "                \"\"\"                \n",
        "                # node_ids = []\n",
        "                # timestamps = []\n",
        "                a, b = (0 - mean_fr) / std_fr, (100 - mean_fr) / std_fr\n",
        "                d = partial(st.truncnorm.rvs, a=a, b=b, loc=mean_fr, scale=std_fr)\n",
        "                \n",
        "                if rhythmic_dict['f'] == \"None\":\n",
        "                    f = h5py.File(\"exc_stim_spikes.h5\", \"r\")\n",
        "                    ts = f['spikes'][\"exc_stim\"]['timestamps']\n",
        "                    nid = f['spikes'][\"exc_stim\"]['node_ids']\n",
        "\n",
        "                    #Creates a noise trace based on the excitatory spike raster.\n",
        "                    z = shift_exc_noise(ts, nid, self.params[\"time\"][\"stop\"], time_shift=self.params[\"inh_shift\"])\n",
        "                    z = np.tile(z,(n_cells,1))\n",
        "                    \n",
        "                    writer = SonataWriter(fname, [\"spikes\", key], [\"timestamps\", \"node_ids\"], [np.float, np.int])\n",
        "                    make_save_spikes(writer, False, d(size=n_cells), numUnits=n_cells,rateProf=z)\n",
        "\n",
        "                else:\n",
        "                    # make an array of modulated sin waves\n",
        "                    # make_save_spikes should be written so that the firing rates are generated\n",
        "                    #    outside instead of inside the function.\n",
        "                    frs = d(size=n_cells)\n",
        "                    \n",
        "                    t = np.arange(0,self.params[\"time\"][\"stop\"],0.001)\n",
        "                    z = np.zeros((n_cells,t.shape[0]))\n",
        "                    P = 0\n",
        "                    for i in np.arange(0,n_cells):\n",
        "                        offset = frs[i]\n",
        "                        A = offset/((1/rhythmic_dict['mod'])-1)\n",
        "                        z[i,:] = A*np.sin((2 * np.pi * rhythmic_dict['f'] * t)+P) + offset\n",
        "\n",
        "                    writer = SonataWriter(fname, [\"spikes\", key], [\"timestamps\", \"node_ids\"], [np.float, np.int])\n",
        "                    make_save_spikes(writer, False, np.ones((n_cells,1)), numUnits=n_cells,rateProf=z)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L5NetParams.json\n",
        "https://github.com/latimerb/L5NeuronSimulation/blob/dea91c052102bb4c2a58b860ebed88b3af4a24bc/L5NeuronSimulation/FullSimulation/L5NetParams.json"
      ],
      "metadata": {
        "id": "L5ieUdAhjWS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"cell\":\n",
        "    {\n",
        "        \"prefix\": \"L5\",\n",
        "        \"dynamic_params\": null,\n",
        "        \"model_template\": \"hoc:L5PCtemplate\",\n",
        "        \"morphology\": null,\n",
        "        \"model_processing\": null,\n",
        "        \"segments_file\": \"L5Segments.csv\"\n",
        "    },\n",
        "\n",
        "    \"lengths\":\n",
        "    {\n",
        "        \"basal_dist\": 4649,\n",
        "        \"basal_prox\": 483,\n",
        "        \"apic\": 7440\n",
        "    },\n",
        "\n",
        "    \"syn_density\":\n",
        "    {\n",
        "        \"exc\": 2.16,\n",
        "        \"inh\": 0.22\n",
        "    },\n",
        "\n",
        "    \"n_soma_syns\": 150,\n",
        "\n",
        "    \"divergence\":\n",
        "    {\n",
        "        \"exc\": {\"min\":2, \"max\":8},\n",
        "        \"peri_inh\": {\"m\":2.8, \"s\":1.9, \"min\":1, \"max\":5},\n",
        "        \"basal_inh\": {\"m\":2.7, \"s\":1.6, \"min\":1 , \"max\":5},\n",
        "        \"apic_inh\": {\"m\":12, \"s\":3, \"min\":6 , \"max\":18}\n",
        "    },\n",
        "\n",
        "    \"groups\":\n",
        "    {\n",
        "        \"cells_per_group\": 100,\n",
        "        \"cluster_radius\": 10,\n",
        "        \"group_radius\": 100\n",
        "    },\n",
        "\n",
        "    \"file_current_clamp\": {\"input_file\":\"None\"},\n",
        "\n",
        "    \"record_cellvars\":\n",
        "    {\n",
        "        \"vars\": [\"v\"],\n",
        "        \"locs\": [\"all\"]\n",
        "    },\n",
        "\n",
        "    \"inh_frs\":\n",
        "    {\n",
        "        \"proximal\": {\"m\":16.9, \"s\":14.3, \"rhythmicity\":{\"f\":\"None\", \"mod\":\"None\"}},\n",
        "        \"distal\": {\"m\":3.9, \"s\":4.9, \"rhythmicity\":{\"f\":16, \"mod\":0.5}}\n",
        "    },\n",
        "\n",
        "    \"time\": {\"start\":0,\"stop\":100},\n",
        "    \"dL\": 5,\n",
        "    \"dt\": 0.1,\n",
        "\n",
        "    \"inh_shift\": 2\n",
        "}"
      ],
      "metadata": {
        "id": "q5NU3kbyjbED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "raster_maker.py\n",
        "https://github.com/latimerb/L5NeuronSimulation/blob/master/L5NeuronSimulation/FullSimulation/raster_maker.py#L199"
      ],
      "metadata": {
        "id": "iLhrwNHojwLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SonataWriter:\n",
        "    \"\"\"Class used to dynamically writing spike rasters to an h5 file.\n",
        "    Attributes\n",
        "    ----------\n",
        "    file : h5py.File\n",
        "        file object being worked on\n",
        "    group : h5py.Group\n",
        "        gropu where the datasets reside\n",
        "    datasets : dict\n",
        "        datasets that are saved to the file\n",
        "    Methods\n",
        "    -------\n",
        "    append_ds(vals, ds)\n",
        "        appends the given values to the end of the given dataset\n",
        "    append_repeat(ds, val, N)\n",
        "        appends the given value N times to the end of the given dataset\n",
        "    close()\n",
        "        close the h5py file\n",
        "    \"\"\"\n",
        "    def __init__(self, f_name, groups, datasets, types):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        f_name : str\n",
        "            name of file location\n",
        "        groups : list\n",
        "            list of group names (str) that are layered into the h5py file\n",
        "            in the order given.\n",
        "        datasets : list\n",
        "            list of dataset names (str)\n",
        "        types : list\n",
        "            list of data types that corresponds to the datasets list\n",
        "        \"\"\"        \n",
        "        self.file = h5py.File(f_name, 'w')\n",
        "\n",
        "        self.group = self.file\n",
        "        for group in groups:\n",
        "            self.group = self.group.create_group(group)\n",
        "\n",
        "        self.datasets = {}\n",
        "        for i, ds in enumerate(datasets):\n",
        "            self.datasets[ds] = self.group.create_dataset(ds, data=[], dtype=types[i], chunks=True, maxshape=(None,))\n",
        "\n",
        "    def append_ds(self, vals, ds):\n",
        "        \"\"\"appends the given values to the end of the given dataset\n",
        "        Parameters\n",
        "        ----------\n",
        "        vals : list\n",
        "            list of values to be appended to the dataset\n",
        "        ds : str\n",
        "            key of the dataset to append to\n",
        "        \"\"\"        \n",
        "        length = len(self.datasets[ds])\n",
        "        self.datasets[ds].resize((length + len(vals), ))\n",
        "        self.datasets[ds][length:] = vals\n",
        "\n",
        "    def append_repeat(self, ds, val, N):\n",
        "        \"\"\"appends the given value N times to the end of the given dataset\n",
        "        Parameters\n",
        "        ----------\n",
        "        ds : str\n",
        "            key of the dataset to append to\n",
        "        val : [type]\n",
        "            value to be appended N times\n",
        "        N : int\n",
        "            number of vals to append to the dataset\n",
        "        \"\"\"        \n",
        "        self.append_ds([val for i in range(N)], ds)\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Closes the h5py File\n",
        "        \"\"\"        \n",
        "        self.file.close()\n",
        "\n",
        "def zscore(x):\n",
        "    \"\"\"z scores the given array\"\"\"\n",
        "    return (x-np.mean(x))/np.std(x)\n",
        "\n",
        "def minmax(x):\n",
        "    \"\"\"min max normalizes the given array\"\"\"\n",
        "    return (x - np.min(x))/(np.max(x)-np.min(x))\n",
        "\n",
        "def moving_average(x, w):\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w\n",
        "\n",
        "def make_noise(num_traces=100,num_samples=4999):\n",
        "    \"\"\"Creates a noise trace used in generating spike rasters.\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_traces : int, optional\n",
        "        number of noise traces to create (first dimension), by default 100\n",
        "    num_samples : int, optional\n",
        "        length of the trace (second dimension), by default 4999\n",
        "    Returns\n",
        "    -------\n",
        "    np.array\n",
        "        noise trace\n",
        "    \"\"\"    \n",
        "    B = [0.049922035, -0.095993537, 0.050612699, -0.004408786]\n",
        "    A = [1, -2.494956002,   2.017265875,  -0.522189400]\n",
        "    invfn = np.zeros((num_traces,num_samples))\n",
        "    for i in np.arange(0,num_traces):\n",
        "        wn = np.random.normal(loc=1,\n",
        " \t\t\t   scale=0.5,size=num_samples+2000)\n",
        "        invfn[i,:] = minmax(ss.lfilter(B, A, wn)[2000:])+0.5                             # Create '1/f' Noise\n",
        "    return invfn\n",
        "\n",
        "\n",
        "def shift_exc_noise(ts, nid, seconds, time_shift=4):\n",
        "    \"\"\"Creates a shifted, min-max normalized average traces of the given spike raster.\n",
        "    Parameters\n",
        "    ----------\n",
        "    ts : list\n",
        "        times (float) where spikes occur\n",
        "    nid : int\n",
        "        node id associated with each spike\n",
        "    seconds : float\n",
        "        length of the raster in seconds\n",
        "    time_shift : int, optional\n",
        "        how many ms to shift the average trace by, by default 4\n",
        "    Returns\n",
        "    -------\n",
        "    [type]\n",
        "        [description]\n",
        "    \"\"\"    \n",
        "    h = np.histogram(ts,bins=np.arange(0,seconds*1000,1))\n",
        "\n",
        "    fr_prof = h[0]/(0.001*(np.max(nid)+1))\n",
        "    wrap = fr_prof[-4:]\n",
        "    fr_prof[4:] = fr_prof[0:-4]\n",
        "    fr_prof[0:4] = wrap\n",
        "\n",
        "    fr_prof = minmax(fr_prof)+0.5\n",
        "    return fr_prof\n",
        "\n",
        "def make_save_spikes(writer, exp, dist, numUnits=100,rateProf=None,start_id=0,start_time=0):\n",
        "    \"\"\"Creates and saves spikes for the given nodes using\n",
        "    the provided noise trace and a random mean firing rate generated with\n",
        "    the given distribution.\n",
        "    Parameters\n",
        "    ----------\n",
        "    writer : SonataWriter\n",
        "        how the spikes are saved\n",
        "    exp : bool\n",
        "        whether the value from dist should be fed to np.exp()\n",
        "    dist : np.array()\n",
        "        array of firing rates of shape (numUnits,)\n",
        "    numUnits : int, optional\n",
        "        number of nodes to generate spikes for, by default 100\n",
        "    rateProf : np.array(), optional\n",
        "        noise trace for each unit must have numUnits rows, by default None\n",
        "    start_id : int, optional\n",
        "        node_id that the first unit/node should be associated with, by default 0\n",
        "    start_time : int, optional\n",
        "        at what time the spikes should start being generated, by default 0\n",
        "    \"\"\"    \n",
        "    \n",
        "    for i in np.arange(0,numUnits):\n",
        "       \n",
        "        try: \n",
        "            r = rateProf[i,:]\n",
        "        except:\n",
        "            import pdb; pdb.set_trace()\n",
        "        r[r<0] = 0#Can't have negative firing rates.\n",
        "        rate_temp=[];simSpks_temp=[]\n",
        "\n",
        "        #Multiplies the noise trace by the randomly generated firing rate.\n",
        "        if exp:\n",
        "            rate_temp = r*np.exp(dist[i])\n",
        "        else:\n",
        "            rate_temp = r*dist[i]\n",
        "\n",
        "        numbPoints = scipy.stats.poisson(rate_temp/1000).rvs()#Poisson number of points\n",
        "\n",
        "        simSpks=np.where(numbPoints>0)[0]\n",
        "\n",
        "        writer.append_repeat(\"node_ids\", i + start_id, len(simSpks))\n",
        "        writer.append_ds(simSpks + start_time, \"timestamps\")"
      ],
      "metadata": {
        "id": "QXCCTgojjwe1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}