{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSOv6mCdEzCnqsR4ojetFw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidfague/Stylized-ReducedOrder-L5-Model/blob/main/Reduction_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assume an entire dendritic tree has been reduced by mapping ion channels and synapses to a new single equivalent cylindrical core conductor (cable) that preserves transfer impedance from the synapse and ion channels to the soma.\n",
        "\n",
        "Introduce branching dendrites back into the new cable."
      ],
      "metadata": {
        "id": "bYTrUrvSP0RC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "LiLOKSX0RmtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neuron\n",
        "\n",
        "# !git clone https://github.com/orena1/neuron_reduce.git\n",
        "# # Go to example folder\n",
        "# %cd neuron_reduce \n",
        "# %cd example\n",
        "# # compile the mod files\n",
        "# !nrnivmodl mod\n",
        "\n",
        "\n",
        "!git clone https://github.com/davidfague/Stylized-ReducedOrder-L5-Model.git\n",
        "\n",
        "%cd Stylized-ReducedOrder-L5-Model/\n",
        "%cd \n",
        "\n",
        "# try to use the neuron_reduce from my github\n",
        "from __future__ import division\n",
        "from test_neuron_reduce.subtree_reductor_func import subtree_reductor\n",
        "#Run the code\n",
        "from __future__ import division\n",
        "from neuron import gui,h\n",
        "import numpy as np\n",
        "# import neuron_reduce\n",
        "import time\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEHzUcSoUO-m",
        "outputId": "36b130c2-f897-4e47-fd9e-94510a903c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neuron\n",
            "  Downloading NEURON-8.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.8/dist-packages (from neuron) (1.22.4)\n",
            "Installing collected packages: neuron\n",
            "Successfully installed neuron-8.2.2\n",
            "Cloning into 'neuron_reduce'...\n",
            "remote: Enumerating objects: 426, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 426 (delta 4), reused 1 (delta 0), pack-reused 413\u001b[K\n",
            "Receiving objects: 100% (426/426), 12.55 MiB | 19.36 MiB/s, done.\n",
            "Resolving deltas: 100% (177/177), done.\n",
            "/content/neuron_reduce\n",
            "/content/neuron_reduce/example\n",
            "/content/neuron_reduce/example\n",
            "Mod files: \"mod/mod/CaDynamics_E2.mod\" \"mod/mod/Ca_HVA.mod\" \"mod/mod/Ca_LVAst.mod\" \"mod/mod/epsp.mod\" \"mod/mod/Ih.mod\" \"mod/mod/Im.mod\" \"mod/mod/K_Pst.mod\" \"mod/mod/K_Tst.mod\" \"mod/mod/Nap_Et2.mod\" \"mod/mod/NaTa_t.mod\" \"mod/mod/NaTs2_t.mod\" \"mod/mod/SK_E2.mod\" \"mod/mod/SKv3_1.mod\"\n",
            "\n",
            "Creating 'x86_64' directory for .o files.\n",
            "\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/Ca_HVA.mod\n",
            " -> \u001b[32mCompiling\u001b[0m mod_func.cpp\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/CaDynamics_E2.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/Ca_LVAst.mod\n",
            "Translating CaDynamics_E2.mod into /content/neuron_reduce/example/x86_64/CaDynamics_E2.c\n",
            "Translating Ca_LVAst.mod into /content/neuron_reduce/example/x86_64/Ca_LVAst.c\n",
            "Thread Safe\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/epsp.mod\n",
            "Translating Ca_HVA.mod into /content/neuron_reduce/example/x86_64/Ca_HVA.c\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/Ih.mod\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/Im.mod\n",
            "Translating epsp.mod into /content/neuron_reduce/example/x86_64/epsp.c\n",
            "Thread Safe\n",
            "Translating Im.mod into /content/neuron_reduce/example/x86_64/Im.c\n",
            "Thread Safe\n",
            "Translating Ih.mod into /content/neuron_reduce/example/x86_64/Ih.c\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/K_Tst.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/K_Pst.mod\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/Nap_Et2.mod\n",
            "Translating K_Tst.mod into /content/neuron_reduce/example/x86_64/K_Tst.c\n",
            "Translating K_Pst.mod into /content/neuron_reduce/example/x86_64/K_Pst.c\n",
            "Thread Safe\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/NaTa_t.mod\n",
            "Translating Nap_Et2.mod into /content/neuron_reduce/example/x86_64/Nap_Et2.c\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/NaTs2_t.mod\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/SK_E2.mod\n",
            "Translating NaTa_t.mod into /content/neuron_reduce/example/x86_64/NaTa_t.c\n",
            "Translating NaTs2_t.mod into /content/neuron_reduce/example/x86_64/NaTs2_t.c\n",
            "Thread Safe\n",
            "Thread Safe\n",
            " -> \u001b[32mNMODL\u001b[0m ../mod/SKv3_1.mod\n",
            " -> \u001b[32mCompiling\u001b[0m CaDynamics_E2.c\n",
            "Translating SK_E2.mod into /content/neuron_reduce/example/x86_64/SK_E2.c\n",
            "Thread Safe\n",
            " -> \u001b[32mCompiling\u001b[0m Ca_HVA.c\n",
            "Translating SKv3_1.mod into /content/neuron_reduce/example/x86_64/SKv3_1.c\n",
            "Thread Safe\n",
            " -> \u001b[32mCompiling\u001b[0m Ca_LVAst.c\n",
            " -> \u001b[32mCompiling\u001b[0m epsp.c\n",
            " -> \u001b[32mCompiling\u001b[0m Ih.c\n",
            " -> \u001b[32mCompiling\u001b[0m Im.c\n",
            " -> \u001b[32mCompiling\u001b[0m K_Pst.c\n",
            " -> \u001b[32mCompiling\u001b[0m K_Tst.c\n",
            " -> \u001b[32mCompiling\u001b[0m Nap_Et2.c\n",
            " -> \u001b[32mCompiling\u001b[0m NaTa_t.c\n",
            " -> \u001b[32mCompiling\u001b[0m NaTs2_t.c\n",
            " -> \u001b[32mCompiling\u001b[0m SK_E2.c\n",
            " -> \u001b[32mCompiling\u001b[0m SKv3_1.c\n",
            " => \u001b[32mLINKING\u001b[0m shared library ./libnrnmech.so\n",
            " => \u001b[32mLINKING\u001b[0m executable ./special LDFLAGS are:    -pthread\n",
            "Successfully created x86_64/special\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### neuron_reduce functions"
      ],
      "metadata": {
        "id": "MhXQEkLzStfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "neuron_reduce functions are used to reduce dendritic trees into single cylindrical cables. neuron_reduce can be found here: https://github.com/orena1/neuron_reduce."
      ],
      "metadata": {
        "id": "A9ieIbUPSknS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### subtree_reductor_func.py"
      ],
      "metadata": {
        "id": "w8j8CM2gTzRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "function subtree_reductor():\n",
        " which reduces a morphologically detailed cell instance into a morphologically\n",
        " simplified cell instance, according to NeuroReduce and merges synapses of the\n",
        " same type (same reverse potential, tau1, and tau2) that are mapped to the same\n",
        " segment. (see more in Readme on tool and usage)\n",
        "\n",
        " usage: For details, see comments in function\n",
        "\n",
        " outputs: reduced cell instance, a new synapses_list, and the netcons_list,\n",
        "          which now corresponds to the new synapses.\n",
        "\n",
        "- The model template file must have an init() function (see example in the\n",
        "  attached model.hoc file) and the following public definitions specifying\n",
        "  sections and section lists accordingly:\n",
        "   public soma, dend, apic ; public all, somatic, apical, basal\n",
        "\n",
        "- Supports numerous types of synapses (two synapses are considered to be of\n",
        "  different types if they are different from each other in at least one of the\n",
        "  following values: reverse potential, tau1, tau2)\n",
        "'''\n",
        "import collections\n",
        "import itertools as it\n",
        "import logging\n",
        "import math\n",
        "import re\n",
        "import cmath\n",
        "\n",
        "import numpy as np\n",
        "import neuron\n",
        "from neuron import h\n",
        "h.load_file(\"stdrun.hoc\")\n",
        "\n",
        "# from .reducing_methods import (reduce_subtree,\n",
        "#                                reduce_synapse,\n",
        "#                                measure_input_impedance_of_subtree,\n",
        "#                                CableParams,\n",
        "#                                SynapseLocation,\n",
        "#                                push_section,\n",
        "#                                )\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "SOMA_LABEL = \"soma\"\n",
        "EXCLUDE_MECHANISMS = ('pas', 'na_ion', 'k_ion', 'ca_ion', 'h_ion', 'ttx_ion', )\n",
        "\n",
        "\n",
        "def create_sections_in_hoc(type_of_section, num, instance_as_str):\n",
        "    '''creates sections in the hoc world according to the given section type and number of sections\n",
        "\n",
        "    in the instance whose name is given as a string\n",
        "    '''\n",
        "    h(\"strdef string\")\n",
        "    h.string = type_of_section\n",
        "    h('{sprint(string, \"create %s[%d]\", string, ' + str(num) + ') }')\n",
        "    h(\"{execute(string, \" + instance_as_str + \")}\")\n",
        "\n",
        "\n",
        "def append_to_section_lists(section, type_of_sectionlist, instance_as_str):\n",
        "    ''' appends given section to the sectionlist of the given type and to the \"all\" sectionlist\n",
        "\n",
        "    in the hoc world in the instance whose name is given as a string\n",
        "    '''\n",
        "    h(\"strdef string\")\n",
        "    h.string = section + \" \" + type_of_sectionlist + \".append()\"\n",
        "    h(\"{execute(string, \" + instance_as_str + \")}\")\n",
        "    h.string = section + \" all.append()\"\n",
        "    h(\"{execute(string, \" + instance_as_str + \")}\")\n",
        "\n",
        "\n",
        "def find_section_number(section):\n",
        "    ''' extracts and returns the section number from the given section object '''\n",
        "    sec_name = h.secname(sec=section)\n",
        "    ints_in_name = re.findall(r'\\d+', sec_name)\n",
        "    sec_num = ints_in_name[len(ints_in_name) - 1]  # extracts section number\n",
        "    return sec_num\n",
        "\n",
        "\n",
        "def calculate_nsegs_from_manual_arg(new_cable_properties, total_segments_wanted):\n",
        "    '''Calculates the number of segments for each section in the reduced model\n",
        "\n",
        "    according to the given total_segments_wanted and the given\n",
        "    new_dends_electrotonic_length (the electrotonic lengths of all the new\n",
        "    sections).  Called when the user chooses to give to the program the\n",
        "    approximate total number of segments that the reduced model should have\n",
        "    (non-default calculation).\n",
        "    '''\n",
        "    # minus one for the one segment of the soma:\n",
        "    total_segments_in_dendrites = total_segments_wanted - 1\n",
        "\n",
        "    # total electrotonic length of reduced dendritic cables\n",
        "    sum_of_lengths = sum(prop.electrotonic_length\n",
        "                         for prop in new_cable_properties)\n",
        "\n",
        "    # the num of segments assigned to each section is in proportion to the\n",
        "    # section's relative contribution to the total electrotonic length in the\n",
        "    # model\n",
        "    dends_nsegs = []\n",
        "    for prop in new_cable_properties:\n",
        "        new_length = prop.electrotonic_length\n",
        "        new_nseg_to_put = int(round((float(new_length) / sum_of_lengths) *\n",
        "                              total_segments_in_dendrites))\n",
        "        if new_nseg_to_put < 1:\n",
        "            new_nseg_to_put = 1\n",
        "        dends_nsegs.append(new_nseg_to_put)\n",
        "    return dends_nsegs\n",
        "\n",
        "\n",
        "def calculate_nsegs_from_lambda(new_cable_properties):\n",
        "    '''calculate the number of segments for each section in the reduced model\n",
        "\n",
        "    according to the length (in microns) and space constant (= lambda - in\n",
        "    microns) that were previously calculated for each section and are given in\n",
        "    subtree_dimensions.  According to this calculation, a segment is formed for\n",
        "    every 0.1 * lambda in a section. (lambda = space constant = electrotonic length unit).\n",
        "    '''\n",
        "    dends_nsegs = []\n",
        "    for cable in new_cable_properties:\n",
        "        # for every unit of electronic length (length/space_constant such units)\n",
        "        # ~10 segments are formed\n",
        "        dends_nsegs.append(int((float(cable.length) / cable.space_const) * 10 / 2) * 2 + 1)\n",
        "    return dends_nsegs\n",
        "\n",
        "\n",
        "def mark_subtree_sections_with_subtree_index(sections_to_delete,\n",
        "                                             section_per_subtree_index,\n",
        "                                             root_sec_of_subtree,\n",
        "                                             mapping_sections_to_subtree_index,\n",
        "                                             section_type,\n",
        "                                             subtree_index):\n",
        "    '''Recursively marks all sections in the subtree as belonging to the given subtree_index\n",
        "\n",
        "    using the given dict mapping_sections_to_subtree_index, as follows:\n",
        "    mapping_sections_to_subtree_index[(<section_type>, <section_number>)] = given subtree_index\n",
        "    '''\n",
        "    sections_to_delete.append(root_sec_of_subtree)\n",
        "    section_per_subtree_index.setdefault(subtree_index, [])\n",
        "    section_per_subtree_index[subtree_index].append(root_sec_of_subtree)\n",
        "\n",
        "    section_num = find_section_number(root_sec_of_subtree)\n",
        "\n",
        "    for child in root_sec_of_subtree.children():\n",
        "        mark_subtree_sections_with_subtree_index(sections_to_delete,\n",
        "                                                 section_per_subtree_index,\n",
        "                                                 child,\n",
        "                                                 mapping_sections_to_subtree_index,\n",
        "                                                 section_type,\n",
        "                                                 subtree_index)\n",
        "    mapping_sections_to_subtree_index[(section_type, section_num)] = subtree_index\n",
        "\n",
        "\n",
        "def find_synapse_loc(synapse_or_segment, mapping_sections_to_subtree_index):\n",
        "    ''' Returns the location  of the given synapse object'''\n",
        "\n",
        "    if not isinstance(synapse_or_segment, neuron.nrn.Segment):\n",
        "        synapse_or_segment = synapse_or_segment.get_segment()\n",
        "\n",
        "    x = synapse_or_segment.x\n",
        "\n",
        "    with push_section(synapse_or_segment.sec):\n",
        "        # extracts the section type (\"soma\", \"apic\", \"dend\") and the section number\n",
        "        # out of the section name\n",
        "        full_sec_name = h.secname()\n",
        "        sec_name_as_list = full_sec_name.split(\".\")\n",
        "        short_sec_name = sec_name_as_list[len(sec_name_as_list) - 1]\n",
        "        section_type = short_sec_name.split(\"[\")[0]\n",
        "        section_num = re.findall(r'\\d+', short_sec_name)[0]\n",
        "\n",
        "    # finds the index of the subtree that this synapse belongs to using the\n",
        "    # given mapping_sections_to_subtree_index which maps sections to the\n",
        "    # subtree indexes that they belong to\n",
        "    if section_type == \"apic\":\n",
        "        subtree_index = mapping_sections_to_subtree_index[(\"apic\", section_num)]\n",
        "    elif section_type == \"dend\":\n",
        "        subtree_index = mapping_sections_to_subtree_index[(\"basal\", section_num)]\n",
        "    else:  # somatic synapse\n",
        "        subtree_index, section_num, x = SOMA_LABEL, 0, 0\n",
        "\n",
        "    return SynapseLocation(subtree_index, int(section_num), x)\n",
        "\n",
        "\n",
        "def find_and_disconnect_axon(soma_ref):\n",
        "    '''Searching for an axon, it can be a child of the soma or a parent of the soma.'''\n",
        "    axon_section, axon_parent, soma_axon_x  = [], False, None\n",
        "\n",
        "    for sec in soma_ref.child:\n",
        "        name = sec.hname().lower()\n",
        "        if 'axon' in name or 'hill' in name:\n",
        "            axon_section.append(sec)\n",
        "            # disconnect axon\n",
        "            soma_axon_x = sec.parentseg().x\n",
        "            sec.push()\n",
        "            h.disconnect()\n",
        "            h.define_shape()\n",
        "\n",
        "    if soma_ref.has_parent():\n",
        "        name = soma_ref.parent().sec.hname().lower()\n",
        "        if 'axon' in name or 'hill' in name:\n",
        "            axon_section.append(soma_ref.parent())\n",
        "            axon_parent = True\n",
        "            soma_axon_x = None\n",
        "            soma_ref.push()\n",
        "            h.disconnect()\n",
        "        else:\n",
        "            raise Exception('Soma has a parent which is not an axon')\n",
        "\n",
        "    if len(axon_section) > 1:\n",
        "        raise Exception('Soma has a two axons')\n",
        "\n",
        "    return axon_section, axon_parent, soma_axon_x\n",
        "\n",
        "\n",
        "def create_segments_to_mech_vals(sections_to_delete,\n",
        "                                 remove_mechs=True,\n",
        "                                 exclude=EXCLUDE_MECHANISMS):\n",
        "    '''This function copy the create a mapping between a dictionary and the mechanisms that it have\n",
        "       plus the values of those mechanisms. It also remove the mechanisms from the model in order to\n",
        "       create a passive model\n",
        "\n",
        "       Arguments:\n",
        "           remove_mechs - False|True\n",
        "               if True remove the mechs after creating the mapping, False - keep the mechs\n",
        "           exclude - List of all the mechs name that should not be removed\n",
        "       '''\n",
        "    exclude = set(exclude)\n",
        "    segment_to_mech_vals, mech_names = {}, set()\n",
        "\n",
        "    for seg in it.chain.from_iterable(sections_to_delete):\n",
        "        segment_to_mech_vals[seg] = {}\n",
        "        for mech in seg:\n",
        "            mech_name = mech.name()\n",
        "            segment_to_mech_vals[seg][mech_name] = {}\n",
        "            for n in dir(mech):\n",
        "                if n.startswith('__') or n in ('next', 'name', 'is_ion', 'segment', ):\n",
        "                    continue\n",
        "\n",
        "                if not n.endswith('_' + mech_name) and not mech_name.endswith('_ion'):\n",
        "                    n += '_' + mech_name\n",
        "\n",
        "                segment_to_mech_vals[seg][mech_name][n] = getattr(seg, n)\n",
        "                mech_names.add(mech_name)\n",
        "\n",
        "    mech_names -= exclude\n",
        "\n",
        "    if remove_mechs:  # Remove all the mechs from the sections\n",
        "        for sec in sections_to_delete:\n",
        "            with push_section(sec):\n",
        "                for mech in mech_names:\n",
        "                    h(\"uninsert \" + mech)\n",
        "\n",
        "    return segment_to_mech_vals\n",
        "\n",
        "\n",
        "def create_seg_to_seg(original_cell,\n",
        "                      section_per_subtree_index,\n",
        "                      roots_of_subtrees,\n",
        "                      mapping_sections_to_subtree_index,\n",
        "                      new_cable_properties,\n",
        "                      has_apical,\n",
        "                      apic,\n",
        "                      basals,\n",
        "                      subtree_ind_to_q,\n",
        "                      mapping_type,\n",
        "                      reduction_frequency):\n",
        "    '''create mapping between segments in the original model to segments in the reduced model\n",
        "\n",
        "       if mapping_type == impedance the mapping will be a response to the\n",
        "       transfer impedance of each segment to the soma (like the synapses)\n",
        "\n",
        "       if mapping_type == distance  the mapping will be a response to the\n",
        "       distance of each segment to the soma (like the synapses) NOT IMPLEMENTED\n",
        "       YET\n",
        "\n",
        "       '''\n",
        "\n",
        "    assert mapping_type == 'impedance', 'distance mapping not implemented yet'\n",
        "    # the keys are the segments of the original model, the values are the\n",
        "    # segments of the reduced model\n",
        "    original_seg_to_reduced_seg = {}\n",
        "    reduced_seg_to_original_seg = collections.defaultdict(list)\n",
        "    for subtree_index in section_per_subtree_index:\n",
        "        for sec in section_per_subtree_index[subtree_index]:\n",
        "            for seg in sec:\n",
        "                synapse_location = find_synapse_loc(seg, mapping_sections_to_subtree_index)\n",
        "                imp_obj, subtree_input_impedance = measure_input_impedance_of_subtree(\n",
        "                    roots_of_subtrees[subtree_index], reduction_frequency)\n",
        "\n",
        "                # if synapse is on the apical subtree\n",
        "                on_basal_subtree = not (has_apical and subtree_index == 0)\n",
        "\n",
        "                mid_of_segment_loc = reduce_synapse(\n",
        "                    original_cell,\n",
        "                    synapse_location,\n",
        "                    on_basal_subtree,\n",
        "                    imp_obj,\n",
        "                    subtree_input_impedance,\n",
        "                    new_cable_properties[subtree_index].electrotonic_length,\n",
        "                    subtree_ind_to_q[subtree_index])\n",
        "\n",
        "                if on_basal_subtree:\n",
        "                    if has_apical:\n",
        "                        new_section_for_synapse = basals[subtree_index - 1]\n",
        "                    else:\n",
        "                        new_section_for_synapse = basals[subtree_index]\n",
        "                else:\n",
        "                    new_section_for_synapse = apic\n",
        "\n",
        "                reduced_seg = new_section_for_synapse(mid_of_segment_loc)\n",
        "                original_seg_to_reduced_seg[seg] = reduced_seg\n",
        "                reduced_seg_to_original_seg[reduced_seg].append(seg)\n",
        "\n",
        "    return original_seg_to_reduced_seg, dict(reduced_seg_to_original_seg)\n",
        "\n",
        "\n",
        "def copy_dendritic_mech(original_seg_to_reduced_seg,\n",
        "                        reduced_seg_to_original_seg,\n",
        "                        apic,\n",
        "                        basals,\n",
        "                        segment_to_mech_vals,\n",
        "                        mapping_type='impedance'):\n",
        "    ''' copies the mechanisms from the original model to the reduced model'''\n",
        "\n",
        "    # copy mechanisms\n",
        "    # this is needed for the case where some segements were not been mapped\n",
        "    mech_names_per_segment = collections.defaultdict(list)\n",
        "    vals_per_mech_per_segment = {}\n",
        "    for reduced_seg, original_segs in reduced_seg_to_original_seg.items():\n",
        "        vals_per_mech_per_segment[reduced_seg] = collections.defaultdict(list)\n",
        "\n",
        "        for original_seg in original_segs:\n",
        "            for mech_name, mech_params in segment_to_mech_vals[original_seg].items():\n",
        "                for param_name, param_value in mech_params.items():\n",
        "                    vals_per_mech_per_segment[reduced_seg][param_name].append(param_value)\n",
        "\n",
        "                mech_names_per_segment[reduced_seg].append(mech_name)\n",
        "                reduced_seg.sec.insert(mech_name)\n",
        "\n",
        "        for param_name, param_values in vals_per_mech_per_segment[reduced_seg].items():\n",
        "            setattr(reduced_seg, param_name, np.mean(param_values))\n",
        "\n",
        "    all_segments = []\n",
        "    if apic is not None:\n",
        "        all_segments.extend(list(apic))\n",
        "\n",
        "    for bas in basals:\n",
        "        all_segments.extend(list(bas))\n",
        "\n",
        "    if len(all_segments) != len(reduced_seg_to_original_seg):\n",
        "        logger.warning('There is no segment to segment copy, it means that some segments in the'\n",
        "                    'reduced model did not receive channels from the original cell.'\n",
        "                    'Trying to compensate by copying channels from neighboring segments')\n",
        "        handle_orphan_segments(original_seg_to_reduced_seg,\n",
        "                               all_segments,\n",
        "                               vals_per_mech_per_segment,\n",
        "                               mech_names_per_segment)\n",
        "\n",
        "\n",
        "def handle_orphan_segments(original_seg_to_reduced_seg,\n",
        "                           all_segments,\n",
        "                           vals_per_mech_per_segment,\n",
        "                           mech_names_per_segment):\n",
        "    ''' This function handle reduced segments that did not had original segments mapped to them'''\n",
        "    # Get all reduced segments that have been mapped by a original model segment\n",
        "    all_mapped_control_segments = original_seg_to_reduced_seg.values()\n",
        "    non_mapped_segments = set(all_segments) - set(all_mapped_control_segments)\n",
        "\n",
        "    for reduced_seg in non_mapped_segments:\n",
        "        seg_secs = list(reduced_seg.sec)\n",
        "        # find valid parent\n",
        "        parent_seg_index = seg_secs.index(reduced_seg) - 1\n",
        "        parent_seg = None\n",
        "        while parent_seg_index > -1:\n",
        "            if seg_secs[parent_seg_index] in all_mapped_control_segments:\n",
        "                parent_seg = seg_secs[parent_seg_index]\n",
        "                break\n",
        "            else:\n",
        "                parent_seg_index -= 1\n",
        "\n",
        "        # find valid child\n",
        "        child_seg_index = seg_secs.index(reduced_seg) + 1\n",
        "        child_seg = None\n",
        "        while child_seg_index < len(seg_secs):\n",
        "            if seg_secs[child_seg_index] in all_mapped_control_segments:\n",
        "                child_seg = seg_secs[child_seg_index]\n",
        "                break\n",
        "            else:\n",
        "                child_seg_index += 1\n",
        "\n",
        "        if not parent_seg and not child_seg:\n",
        "            raise Exception(\"no child seg nor parent seg, with active channels, was found\")\n",
        "\n",
        "        if parent_seg and not child_seg:\n",
        "            for mech in mech_names_per_segment[parent_seg]:\n",
        "                reduced_seg.sec.insert(mech)\n",
        "            for n in vals_per_mech_per_segment[parent_seg]:\n",
        "                setattr(reduced_seg, n, np.mean(vals_per_mech_per_segment[parent_seg][n]))\n",
        "\n",
        "        if not parent_seg and child_seg:\n",
        "            for mech in mech_names_per_segment[child_seg]:\n",
        "                reduced_seg.sec.insert(mech)\n",
        "            for n in vals_per_mech_per_segment[child_seg]:\n",
        "                setattr(reduced_seg, n, np.mean(vals_per_mech_per_segment[child_seg][n]))\n",
        "\n",
        "        # if both parent and child were found, we add to the segment all the mech in both\n",
        "        # this is just a decision\n",
        "\n",
        "        if parent_seg and child_seg:\n",
        "            for mech in set(mech_names_per_segment[child_seg]) & set(mech_names_per_segment[parent_seg]):\n",
        "                reduced_seg.sec.insert(mech)\n",
        "\n",
        "            for n in vals_per_mech_per_segment[child_seg]:\n",
        "                child_mean = np.mean(vals_per_mech_per_segment[child_seg][n])\n",
        "                if n in vals_per_mech_per_segment[parent_seg]:\n",
        "                    parent_mean = np.mean(vals_per_mech_per_segment[parent_seg][n])\n",
        "                    setattr(reduced_seg, n, (child_mean + parent_mean) / 2)\n",
        "                else:\n",
        "                    setattr(reduced_seg, n, child_mean)\n",
        "\n",
        "            for n in vals_per_mech_per_segment[parent_seg]:\n",
        "                parent_mean = np.mean(vals_per_mech_per_segment[parent_seg][n])\n",
        "                if n in vals_per_mech_per_segment[child_seg]:\n",
        "                    child_mean = np.mean(vals_per_mech_per_segment[child_seg][n])\n",
        "                    setattr(reduced_seg, n, (child_mean + parent_mean) / 2)\n",
        "                else:\n",
        "                    setattr(reduced_seg, n, parent_mean)\n",
        "\n",
        "\n",
        "def add_PP_properties_to_dict(PP, PP_params_dict):\n",
        "    '''\n",
        "    add the propeties of a point process to PP_params_dict.\n",
        "    The only propeties added to the dictionary are those worth comparing\n",
        "    '''\n",
        "    skipped_params = {\"Section\", \"allsec\", \"baseattr\", \"cas\", \"g\", \"get_loc\", \"has_loc\", \"hname\",\n",
        "                      'hocobjptr', \"i\", \"loc\", \"next\", \"ref\", \"same\", \"setpointer\", \"state\",\n",
        "                      \"get_segment\",\n",
        "                      }\n",
        "    PP_params = []\n",
        "    for param in dir(PP):\n",
        "        if param.startswith(\"__\") or param in skipped_params:\n",
        "            continue\n",
        "        PP_params.append(param)\n",
        "    PP_params_dict[type_of_point_process(PP)] = PP_params\n",
        "\n",
        "\n",
        "def type_of_point_process(PP):\n",
        "    s = PP.hname()\n",
        "    ix = PP.hname().find(\"[\")\n",
        "    return s[:ix]\n",
        "\n",
        "\n",
        "def apply_params_to_section(name, type_of_sectionlist, instance_as_str, section, cable_params, nseg):\n",
        "    section.L = cable_params.length\n",
        "    section.diam = cable_params.diam\n",
        "    section.nseg = nseg\n",
        "\n",
        "    append_to_section_lists(name, type_of_sectionlist, instance_as_str)\n",
        "\n",
        "    section.insert('pas')\n",
        "    section.cm = cable_params.cm\n",
        "    section.g_pas = 1.0 / cable_params.rm\n",
        "    section.Ra = cable_params.ra\n",
        "    section.e_pas = cable_params.e_pas\n",
        "\n",
        "\n",
        "def calculate_subtree_q(root, reduction_frequency):\n",
        "    rm = 1.0 / root.g_pas\n",
        "    rc = rm * (float(root.cm) / 1000000)\n",
        "    angular_freq = 2 * math.pi * reduction_frequency\n",
        "    q_imaginary = angular_freq * rc\n",
        "    q_subtree = complex(1, q_imaginary)   # q=1+iwRC\n",
        "    q_subtree = cmath.sqrt(q_subtree)\n",
        "    return q_subtree\n",
        "\n",
        "\n",
        "def synapse_properties_match(synapse, PP, PP_params_dict):\n",
        "    if PP.hname()[:PP.hname().rindex('[')] != synapse.hname()[:synapse.hname().rindex('[')]:\n",
        "        return False\n",
        "    for param in PP_params_dict[type_of_point_process(PP)]:\n",
        "        if(param not in ['rng'] and  # https://github.com/neuronsimulator/nrn/issues/136\n",
        "           str(type(getattr(PP, param))) != \"<type 'hoc.HocObject'>\" and  # ignore hoc objects\n",
        "           getattr(PP, param) != getattr(synapse, param)):\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def load_model(model_filename):\n",
        "    model_obj_name = model_filename.split(\".\")[0].split('/')[-1]\n",
        "    if h.name_declared(model_obj_name) == 0:\n",
        "        logger.debug(\"loading template '%s'\" % model_obj_name)\n",
        "        if model_filename == 'model.hoc':\n",
        "            logger.debug(\"loading default reduced model\")\n",
        "            load_default_model()\n",
        "        else:\n",
        "            h.load_file(model_filename)\n",
        "    else:\n",
        "        logger.info(\"The template '%s' is already defined... not loading.\" % model_obj_name)\n",
        "    return model_obj_name\n",
        "\n",
        "\n",
        "def gather_subtrees(soma_ref):\n",
        "    '''get all the subtrees of the soma\n",
        "\n",
        "    assumes the axon is already disconnected\n",
        "    return (list(roots_of_subtrees), list(num_of_subtrees))\n",
        "    where:\n",
        "      roots_of_subtrees holds the root sections of each of the soma's subtrees\n",
        "        note: The apical, if it exists, has been moved to the front\n",
        "      num_of_subtrees correctly the number of subtrees, excluding the axon\n",
        "    '''\n",
        "\n",
        "    roots_of_subtrees = []\n",
        "    num_of_subtrees = []\n",
        "    for i in range(int(soma_ref.nchild())):\n",
        "        if 'soma' in str(soma_ref.child[i]):\n",
        "            logger.warning(\"soma is child, ignore - not tested yet\")\n",
        "            continue\n",
        "        num_of_subtrees.append(i)\n",
        "        roots_of_subtrees.append(soma_ref.child[i])\n",
        "\n",
        "    # assuming up to one apical tree\n",
        "    ix_of_apical = None\n",
        "    for i in num_of_subtrees:\n",
        "        if 'apic' in roots_of_subtrees[i].hname():\n",
        "            assert ix_of_apical is None, 'Multiple apical dendrites not supported'\n",
        "            ix_of_apical = i\n",
        "\n",
        "    if ix_of_apical is not None:\n",
        "        roots_of_subtrees = ([roots_of_subtrees[ix_of_apical]] +\n",
        "                             roots_of_subtrees[:ix_of_apical] +\n",
        "                             roots_of_subtrees[ix_of_apical + 1:])\n",
        "    return roots_of_subtrees, num_of_subtrees\n",
        "\n",
        "\n",
        "def gather_cell_subtrees(roots_of_subtrees):\n",
        "    # dict that maps section indexes to the subtree index they are in: keys are\n",
        "    # string tuples: (\"apic\"/\"basal\", orig_section_index) , values are ints:\n",
        "    # subtree_instance_index\n",
        "    sections_to_delete = []\n",
        "    section_per_subtree_index = {}\n",
        "    mapping_sections_to_subtree_index = {}\n",
        "    for i, soma_child in enumerate(roots_of_subtrees):\n",
        "        # inserts each section in this subtree into the above dict, which maps\n",
        "        # it to the subtree index\n",
        "        if 'apic' in soma_child.hname():\n",
        "            assert i == 0, ('The apical is not the first child of the soma! '\n",
        "                            'a code refactoring is needed in order to accept it')\n",
        "            mark_subtree_sections_with_subtree_index(sections_to_delete,\n",
        "                                                     section_per_subtree_index,\n",
        "                                                     soma_child,\n",
        "                                                     mapping_sections_to_subtree_index,\n",
        "                                                     \"apic\",\n",
        "                                                     i)\n",
        "        elif 'dend' in soma_child.hname() or 'basal' in soma_child.hname():\n",
        "            mark_subtree_sections_with_subtree_index(sections_to_delete,\n",
        "                                                     section_per_subtree_index,\n",
        "                                                     soma_child,\n",
        "                                                     mapping_sections_to_subtree_index,\n",
        "                                                     \"basal\",\n",
        "                                                     i)\n",
        "\n",
        "    return sections_to_delete, section_per_subtree_index, mapping_sections_to_subtree_index\n",
        "\n",
        "\n",
        "def create_reduced_cell(soma_cable,\n",
        "                        has_apical,\n",
        "                        original_cell,\n",
        "                        model_obj_name,\n",
        "                        new_cable_properties,\n",
        "                        new_cables_nsegs,\n",
        "                        subtrees_xs):\n",
        "    h(\"objref reduced_cell\")\n",
        "    h(\"reduced_cell = new \" + model_obj_name + \"()\")\n",
        "\n",
        "    create_sections_in_hoc(\"soma\", 1, \"reduced_cell\")\n",
        "\n",
        "    soma = original_cell.soma[0] if original_cell.soma.hname()[-1] == ']' else original_cell.soma\n",
        "    append_to_section_lists(\"soma[0]\", \"somatic\", \"reduced_cell\")\n",
        "\n",
        "    if has_apical:  # creates reduced apical cable if apical subtree existed\n",
        "        create_sections_in_hoc(\"apic\", 1, \"reduced_cell\")\n",
        "        apic = h.reduced_cell.apic[0]\n",
        "        num_of_basal_subtrees = len(new_cable_properties) - 1\n",
        "\n",
        "        cable_params = new_cable_properties[0]\n",
        "        nseg = new_cables_nsegs[0]\n",
        "        apply_params_to_section(\"apic[0]\", \"apical\", \"reduced_cell\",\n",
        "                                apic, cable_params, nseg)\n",
        "        apic.connect(soma, subtrees_xs[0], 0)\n",
        "    else:\n",
        "        apic = None\n",
        "        num_of_basal_subtrees = len(new_cable_properties)\n",
        "\n",
        "    # creates reduced basal cables\n",
        "    create_sections_in_hoc(\"dend\", num_of_basal_subtrees, \"reduced_cell\")\n",
        "    basals = [h.reduced_cell.dend[i] for i in range(num_of_basal_subtrees)]\n",
        "\n",
        "    for i in range(num_of_basal_subtrees):\n",
        "        if has_apical:\n",
        "            index_in_reduced_cables_dimensions = i + 1\n",
        "        else:\n",
        "            index_in_reduced_cables_dimensions = i\n",
        "\n",
        "        cable_params = new_cable_properties[index_in_reduced_cables_dimensions]\n",
        "        nseg = new_cables_nsegs[index_in_reduced_cables_dimensions]\n",
        "\n",
        "        apply_params_to_section(\"dend[\" + str(i) + \"]\", \"basal\", \"reduced_cell\",\n",
        "                                basals[i], cable_params, nseg)\n",
        "\n",
        "        basals[i].connect(soma, subtrees_xs[index_in_reduced_cables_dimensions], 0)\n",
        "\n",
        "    # create cell python template\n",
        "    cell = Neuron(h.reduced_cell)\n",
        "    cell.soma = original_cell.soma\n",
        "    cell.apic = apic\n",
        "\n",
        "    return cell, basals\n",
        "\n",
        "\n",
        "def merge_and_add_synapses(num_of_subtrees,\n",
        "                           new_cable_properties,\n",
        "                           PP_params_dict,\n",
        "                           synapses_list,\n",
        "                           mapping_sections_to_subtree_index,\n",
        "                           netcons_list,\n",
        "                           has_apical,\n",
        "                           roots_of_subtrees,\n",
        "                           original_cell,\n",
        "                           basals,\n",
        "                           cell,\n",
        "                           reduction_frequency):\n",
        "    # dividing the original synapses into baskets, so that all synapses that are\n",
        "    # on the same subtree will be together in the same basket\n",
        "\n",
        "    # a list of baskets of synapses, each basket in the list will hold the\n",
        "    # synapses of the subtree of the corresponding basket index\n",
        "    baskets = [[] for _ in num_of_subtrees]\n",
        "    soma_synapses_syn_to_netcon = {}\n",
        "\n",
        "    for syn_index, synapse in enumerate(synapses_list):\n",
        "        synapse_location = find_synapse_loc(synapse, mapping_sections_to_subtree_index)\n",
        "\n",
        "        # for a somatic synapse\n",
        "        # TODO: 'axon' is never returned by find_synapse_loc...\n",
        "        if synapse_location.subtree_index in (SOMA_LABEL, 'axon'):\n",
        "            soma_synapses_syn_to_netcon[synapse] = netcons_list[syn_index]\n",
        "        else:\n",
        "            baskets[synapse_location.subtree_index].append((synapse, synapse_location, syn_index))\n",
        "\n",
        "    # mapping (non-somatic) synapses to their new location on the reduced model\n",
        "    # (the new location is the exact location of the middle of the segment they\n",
        "    # were mapped to, in order to enable merging)\n",
        "    new_synapses_list, subtree_ind_to_q = [], {}\n",
        "    for subtree_index in num_of_subtrees:\n",
        "        imp_obj, subtree_input_impedance = measure_input_impedance_of_subtree(\n",
        "            roots_of_subtrees[subtree_index], reduction_frequency)\n",
        "        subtree_ind_to_q[subtree_index] = calculate_subtree_q(\n",
        "            roots_of_subtrees[subtree_index], reduction_frequency)\n",
        "\n",
        "        # iterates over the synapses in the curr basket\n",
        "        for synapse, synapse_location, syn_index in baskets[subtree_index]:\n",
        "            on_basal_subtree = not (has_apical and subtree_index == 0)\n",
        "\n",
        "            # \"reduces\" the synapse - finds this synapse's new \"merged\"\n",
        "            # location on its corresponding reduced cable\n",
        "            x = reduce_synapse(original_cell,\n",
        "                               synapse_location,\n",
        "                               on_basal_subtree,\n",
        "                               imp_obj,\n",
        "                               subtree_input_impedance,\n",
        "                               new_cable_properties[subtree_index].electrotonic_length,\n",
        "                               subtree_ind_to_q[subtree_index])\n",
        "\n",
        "            # find the section of the synapse\n",
        "            if on_basal_subtree:\n",
        "                if has_apical:\n",
        "                    section_for_synapse = basals[subtree_index - 1]\n",
        "                else:\n",
        "                    section_for_synapse = basals[subtree_index]\n",
        "            else:\n",
        "                section_for_synapse = cell.apic\n",
        "\n",
        "            # go over all point processes in this segment and see whether one\n",
        "            # of them has the same proporties of this synapse\n",
        "            # If there's such a synapse link the original NetCon with this point processes\n",
        "            # If not, move the synapse to this segment.\n",
        "            for PP in section_for_synapse(x).point_processes():\n",
        "                if type_of_point_process(PP) not in PP_params_dict:\n",
        "                    add_PP_properties_to_dict(PP, PP_params_dict)\n",
        "\n",
        "                if synapse_properties_match(synapse, PP, PP_params_dict):\n",
        "                    netcons_list[syn_index].setpost(PP)\n",
        "                    break\n",
        "            else:  # If for finish the loop -> first appearance of this synapse\n",
        "                synapse.loc(x, sec=section_for_synapse)\n",
        "                new_synapses_list.append(synapse)\n",
        "\n",
        "    # merging somatic and axonal synapses\n",
        "    synapses_per_seg = collections.defaultdict(list)\n",
        "    for synapse in soma_synapses_syn_to_netcon:\n",
        "        seg_pointer = synapse.get_segment()\n",
        "\n",
        "        for PP in synapses_per_seg[seg_pointer]:\n",
        "            if type_of_point_process(PP) not in PP_params_dict:\n",
        "                add_PP_properties_to_dict(PP, PP_params_dict)\n",
        "\n",
        "            if synapse_properties_match(synapse, PP, PP_params_dict):\n",
        "                soma_synapses_syn_to_netcon[synapse].setpost(PP)\n",
        "                break\n",
        "        else:  # If for finish the loop -> first appearance of this synapse\n",
        "            synapse.loc(seg_pointer.x, sec=seg_pointer.sec)\n",
        "            new_synapses_list.append(synapse)\n",
        "            synapses_per_seg[seg_pointer].append(synapse)\n",
        "\n",
        "    return new_synapses_list, subtree_ind_to_q\n",
        "\n",
        "def textify_seg_to_seg(segs):\n",
        "    '''convert segment dictionary to text'''\n",
        "    ret = {str(k): str(v) for k, v in segs.items()}\n",
        "    return ret\n",
        "   \n",
        "def subtree_reductor(original_cell,\n",
        "                     synapses_list,\n",
        "                     netcons_list,\n",
        "                     reduction_frequency,\n",
        "                     model_filename='model.hoc',\n",
        "                     total_segments_manual=-1,\n",
        "                     PP_params_dict=None,\n",
        "                     mapping_type='impedance',\n",
        "                     return_seg_to_seg=False\n",
        "                     ):\n",
        "\n",
        "    '''\n",
        "    Receives an instance of a cell with a loaded full morphology, a list of\n",
        "    synapse objects, a list of NetCon objects (the i'th netcon in the list\n",
        "    should correspond to the i'th synapse), the filename (string) of the model\n",
        "    template hoc file that the cell was instantiated from, the desired\n",
        "    reduction frequency as a float, optional parameter for the approximate\n",
        "    desired number of segments in the new model (if this parameter is empty,\n",
        "    the number of segments will be such that there is a segment for every 0.1\n",
        "    lambda), and an optional param for the point process to be compared before\n",
        "    deciding on whether to merge a synapse or not and reduces the cell (using\n",
        "    the given reduction_frequency). Creates a reduced instance using the model\n",
        "    template in the file whose filename is given as a parameter, and merges\n",
        "    synapses of the same type that get mapped to the same segment\n",
        "    (same \"reduced\" synapse object for them all, but different NetCon objects).\n",
        "\n",
        "\n",
        "\n",
        "    model_filename : model.hoc  will use a default template\n",
        "    total_segments_manual: sets the number of segments in the reduced model\n",
        "                           can be either -1, a float between 0 to 1, or an int\n",
        "                           if total_segments_manual = -1 will do automatic segmentation\n",
        "                           if total_segments_manual>1 will set the number of segments\n",
        "                           in the reduced model to total_segments_manual\n",
        "                           if 0>total_segments_manual>1 will automatically segment the model\n",
        "                           but if the automatic segmentation will produce a segment number that\n",
        "                           is lower than original_number_of_segments*total_segments_manual it\n",
        "                           will set the number of segments in the reduced model to:\n",
        "                           original_number_of_segments*total_segments_manual\n",
        "    return_seg_to_seg: if True the function will also return a textify version of the mapping\n",
        "                       between the original segments to the reduced segments \n",
        "\n",
        "\n",
        "    Returns the new reduced cell, a list of the new synapses, and the list of\n",
        "    the inputted netcons which now have connections with the new synapses.\n",
        "\n",
        "    Notes:\n",
        "    1) The original cell instance, synapses and Netcons given as arguments are altered\n",
        "    by the function and cannot be used outside of it in their original context.\n",
        "    2) Synapses are determined to be of the same type and mergeable if their reverse\n",
        "    potential, tau1 and tau2 values are identical.\n",
        "    3) Merged synapses are assigned a single new synapse object that represents them\n",
        "    all, but keep their original NetCon objects. Each such NetCon now connects the\n",
        "    original synapse's NetStim with\n",
        "    the reduced synapse.\n",
        "    '''\n",
        "    if PP_params_dict is None:\n",
        "        PP_params_dict = {}\n",
        "\n",
        "    h.init()\n",
        "\n",
        "    model_obj_name = load_model(model_filename)\n",
        "\n",
        "    # finds soma properties\n",
        "    soma = original_cell.soma[0] if original_cell.soma.hname()[-1] == ']' else original_cell.soma\n",
        "\n",
        "    soma_cable = CableParams(length=soma.L, diam=soma.diam, space_const=None,\n",
        "                             cm=soma.cm, rm=1.0 / soma.g_pas, ra=soma.Ra, e_pas=soma.e_pas,\n",
        "                             electrotonic_length=None)\n",
        "\n",
        "    has_apical = len(list(original_cell.apical)) != 0\n",
        "\n",
        "    soma_ref = h.SectionRef(sec=soma)\n",
        "    axon_section, axon_is_parent, soma_axon_x = find_and_disconnect_axon(soma_ref)\n",
        "    roots_of_subtrees, num_of_subtrees = gather_subtrees(soma_ref)\n",
        "\n",
        "    sections_to_delete, section_per_subtree_index, mapping_sections_to_subtree_index = \\\n",
        "        gather_cell_subtrees(roots_of_subtrees)\n",
        "\n",
        "    # preparing for reduction\n",
        "\n",
        "    # remove active conductances and get seg_to_mech dictionary\n",
        "    segment_to_mech_vals = create_segments_to_mech_vals(sections_to_delete)\n",
        "\n",
        "    # disconnects all the subtrees from the soma\n",
        "    subtrees_xs = []\n",
        "    for subtree_root in roots_of_subtrees:\n",
        "        subtrees_xs.append(subtree_root.parentseg().x)\n",
        "        h.disconnect(sec=subtree_root)\n",
        "\n",
        "    # reducing the subtrees\n",
        "    new_cable_properties = [reduce_subtree(roots_of_subtrees[i], reduction_frequency)\n",
        "                            for i in num_of_subtrees]\n",
        "\n",
        "    if total_segments_manual > 1:\n",
        "        new_cables_nsegs = calculate_nsegs_from_manual_arg(new_cable_properties,\n",
        "                                                           total_segments_manual)\n",
        "    else:\n",
        "        new_cables_nsegs = calculate_nsegs_from_lambda(new_cable_properties)\n",
        "        if total_segments_manual > 0:\n",
        "            original_cell_seg_n = (sum(i.nseg for i in list(original_cell.basal)) +\n",
        "                                   sum(i.nseg for i in list(original_cell.apical))\n",
        "                                   )\n",
        "            min_reduced_seg_n = int(round((total_segments_manual * original_cell_seg_n)))\n",
        "            if sum(new_cables_nsegs) < min_reduced_seg_n:\n",
        "                logger.debug(\"number of segments calculated using lambda is {}, \"\n",
        "                      \"the original cell had {} segments.  \"\n",
        "                      \"The min reduced segments is set to {}% of reduced cell segments\".format(\n",
        "                          sum(new_cables_nsegs),\n",
        "                          original_cell_seg_n,\n",
        "                          total_segments_manual * 100))\n",
        "                logger.debug(\"the reduced cell nseg is set to %s\" % min_reduced_seg_n)\n",
        "                new_cables_nsegs = calculate_nsegs_from_manual_arg(new_cable_properties,\n",
        "                                                                   min_reduced_seg_n)\n",
        "\n",
        "    cell, basals = create_reduced_cell(soma_cable,\n",
        "                                       has_apical,\n",
        "                                       original_cell,\n",
        "                                       model_obj_name,\n",
        "                                       new_cable_properties,\n",
        "                                       new_cables_nsegs,\n",
        "                                       subtrees_xs)\n",
        "\n",
        "    new_synapses_list, subtree_ind_to_q = merge_and_add_synapses(\n",
        "        num_of_subtrees,\n",
        "        new_cable_properties,\n",
        "        PP_params_dict,\n",
        "        synapses_list,\n",
        "        mapping_sections_to_subtree_index,\n",
        "        netcons_list,\n",
        "        has_apical,\n",
        "        roots_of_subtrees,\n",
        "        original_cell,\n",
        "        basals,\n",
        "        cell,\n",
        "        reduction_frequency)\n",
        "\n",
        "    # create segment to segment mapping\n",
        "    original_seg_to_reduced_seg, reduced_seg_to_original_seg = create_seg_to_seg(\n",
        "        original_cell,\n",
        "        section_per_subtree_index,\n",
        "        roots_of_subtrees,\n",
        "        mapping_sections_to_subtree_index,\n",
        "        new_cable_properties,\n",
        "        has_apical,\n",
        "        cell.apic,\n",
        "        basals,\n",
        "        subtree_ind_to_q,\n",
        "        mapping_type,\n",
        "        reduction_frequency)\n",
        "\n",
        "    # copy active mechanisms\n",
        "    copy_dendritic_mech(original_seg_to_reduced_seg,\n",
        "                        reduced_seg_to_original_seg,\n",
        "                        cell.apic,\n",
        "                        basals,\n",
        "                        segment_to_mech_vals,\n",
        "                        mapping_type)\n",
        "    \n",
        "    if return_seg_to_seg:\n",
        "        original_seg_to_reduced_seg_text = textify_seg_to_seg(original_seg_to_reduced_seg)\n",
        "\n",
        "    # Connect axon back to the soma\n",
        "    if len(axon_section) > 0:\n",
        "        if axon_is_parent:\n",
        "            soma.connect(axon_section[0])\n",
        "        else:\n",
        "            axon_section[0].connect(soma, soma_axon_x)\n",
        "\n",
        "    # Now we delete the original model\n",
        "    for section in sections_to_delete:\n",
        "        with push_section(section):\n",
        "            h.delete_section()\n",
        "\n",
        "    cell.axon = axon_section\n",
        "    cell.dend = cell.hoc_model.dend\n",
        "\n",
        "    with push_section(cell.hoc_model.soma[0]):\n",
        "        h.delete_section()\n",
        "    if return_seg_to_seg:\n",
        "        return cell, new_synapses_list, netcons_list, original_seg_to_reduced_seg_text\n",
        "    else:\n",
        "        return cell, new_synapses_list, netcons_list\n",
        "\n",
        "\n",
        "class Neuron(object):\n",
        "    'Python neuron class for hoc models'\n",
        "    def __init__(self, model):\n",
        "        self.hoc_model = model\n",
        "        self.soma = None\n",
        "        self.dend = None\n",
        "        self.apic = None\n",
        "        self.axon = None\n",
        "\n",
        "\n",
        "def load_default_model():\n",
        "    h('''begintemplate model\n",
        "\n",
        "public init, biophys, geom_nseg, delete_axon, finish_creating_model_after_loading_morphology\n",
        "\n",
        "public soma, dend, apic, axon  // sections\n",
        "public all, somatic, apical, axonal, basal // section lists\n",
        "objref all, somatic, apical, axonal, basal, this\n",
        "\n",
        "proc init() {\n",
        "    all = new SectionList()\n",
        "    somatic = new SectionList()\n",
        "    basal = new SectionList()\n",
        "    apical = new SectionList()\n",
        "    axonal = new SectionList()\n",
        "\n",
        "    forall delete_section()\n",
        "    StepDist = 60 // human cells have no spines in their first 60 um\n",
        "                                // from soma - see Benavides-Piccione 2013\n",
        "    F_Spines = 1.9       //As calculated - see detailes in Eyal 2015\n",
        "\n",
        "    CM =0.45\t// uF/cm2\n",
        "    RM = 38907\n",
        "    RA = 203\n",
        "    E_PAS =  -86\n",
        "\n",
        "}\n",
        "\n",
        "create soma[1], dend[1], apic[1], axon[1]\n",
        "\n",
        "//external lambda_f\n",
        "proc geom_nseg() {\n",
        "    soma distance()\n",
        "\n",
        "    forsec all {\n",
        "        RA_calc = RA\n",
        "        RM_calc = RM*F_Spines\n",
        "        if (distance(1)>StepDist){\n",
        "            RA_calc = RA\n",
        "            RM_calc = RM*F_Spines\n",
        "        }\n",
        "        d = diam\n",
        "        lambda = sqrt(RM_calc/RA_calc*d/10000/4)*10000\n",
        "        nseg = int(L/lambda*10/2)*2+1\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "proc biophys() {\n",
        "    forsec all {\n",
        "        insert pas\n",
        "        cm =CM\n",
        "        g_pas=1/RM\n",
        "        Ra = RA\n",
        "        e_pas = E_PAS\n",
        "    }\n",
        "\n",
        "    soma distance()\n",
        "\n",
        "    forsec basal {\n",
        "        if (distance(0.5)>StepDist) {\n",
        "            L = L*F_Spines^(2/3)\n",
        "            diam = diam*(F_Spines^(1/3))\n",
        "        }\n",
        "    }\n",
        "    forsec apical {\n",
        "        if (distance(0.5)>StepDist) {\n",
        "            L = L*F_Spines^(2/3)\n",
        "            diam = diam*(F_Spines^(1/3))\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "proc delete_axon(){\n",
        "    forsec axonal{delete_section()}\n",
        "}\n",
        "\n",
        "\n",
        "proc complete_full_model_creation() {\n",
        "    geom_nseg()      \t\t             // calculates num of segments\n",
        "    delete_axon()\t\t                     // deletes the axon\n",
        "    biophys()\t\t\t             // increases cell dimensions to account for spines\n",
        "}\n",
        "\n",
        "endtemplate model''')"
      ],
      "metadata": {
        "id": "JsHPJzM3Urm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### reducing_methods.py"
      ],
      "metadata": {
        "id": "XrCUEK40T2v1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This file contains the reduction algorithm itself\n",
        "added the method by Guy to find L and X\n",
        "'''\n",
        "import collections\n",
        "import contextlib\n",
        "import logging\n",
        "import math\n",
        "import cmath\n",
        "\n",
        "from neuron import h\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "CableParams = collections.namedtuple('CableParams',\n",
        "                                     'length, diam, space_const,'\n",
        "                                     'cm, rm, ra, e_pas, electrotonic_length')\n",
        "SynapseLocation = collections.namedtuple('SynapseLocation', 'subtree_index, section_num, x')\n",
        "\n",
        "h('''obfunc lowest_impedance_recursive() { local lowest_impedance, lowest_phase, i   localobj curr_subtree_root, sref1, lowest_imp_vec, lowest_child_subtree_impedance, imp_obj\n",
        "    curr_subtree_root = $o1  // in the first call to the function, this is a root section of a dendritic trunk\n",
        "    imp_obj = $o2\n",
        "    curr_subtree_root.sec {\n",
        "        lowest_impedance = imp_obj.transfer(1) // farthest tip of the the curr root section\n",
        "        lowest_phase = imp_obj.transfer_phase(1)\n",
        "    }\n",
        "\n",
        "    if (curr_subtree_root.nchild != 0) { // if the curr section has child sections\n",
        "        for i=0, curr_subtree_root.nchild-1 curr_subtree_root.child[i] {  // for each child of the root, finds the lowest impedance within the subtree whose root is the curr child (in relation to the proximal tip in the curr root child)\n",
        "            curr_subtree_root.child[i] sref1 = new SectionRef()\n",
        "            lowest_child_subtree_impedance = lowest_impedance_recursive(sref1, imp_obj) // recursively returns the lowest transfer impedance and transfer phase within the curr subtree as a vector\n",
        "            if (lowest_child_subtree_impedance.x[0] < lowest_impedance) {\n",
        "                lowest_impedance = lowest_child_subtree_impedance.x[0]\n",
        "                lowest_phase = lowest_child_subtree_impedance.x[1]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    lowest_imp_vec = new Vector(2)\n",
        "    lowest_imp_vec.x[0] = lowest_impedance\n",
        "    lowest_imp_vec.x[1] = lowest_phase\n",
        "    return lowest_imp_vec\n",
        "}''')\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def push_section(section):\n",
        "    '''push a section onto the top of the NEURON stack, pop it when leaving the context'''\n",
        "    section.push()\n",
        "    yield\n",
        "    h.pop_section()\n",
        "\n",
        "\n",
        "def _get_subtree_biophysical_properties(subtree_root_ref, frequency):\n",
        "    ''' gets the biophysical cable properties (Rm, Ra, Rc) and q\n",
        "\n",
        "    for the subtree to be reduced according to the properties of the root section of the subtree\n",
        "    '''\n",
        "    section = subtree_root_ref.sec\n",
        "\n",
        "    rm = 1.0 / section.g_pas  # in ohm * cm^2\n",
        "    # in secs, with conversion of the capacitance from uF/cm2 to F/cm2\n",
        "    RC = rm * (float(section.cm) / 1000000)\n",
        "\n",
        "    # defining q=sqrt(1+iwRC))\n",
        "    angular_freq = 2 * math.pi * frequency   # = w\n",
        "    q_imaginary = angular_freq * RC\n",
        "    q = complex(1, q_imaginary)   # q=1+iwRC\n",
        "    q = cmath.sqrt(q)\t\t# q = sqrt(1+iwRC)\n",
        "\n",
        "    return (section.cm,\n",
        "            rm,\n",
        "            section.Ra,  # in ohm * cm\n",
        "            section.e_pas,\n",
        "            q)\n",
        "\n",
        "\n",
        "def find_lowest_subtree_impedance(subtree_root_ref, imp_obj):\n",
        "    '''\n",
        "    finds the segment in the subtree with the lowest transfer impedance in\n",
        "    relation to the proximal-to-soma end of the given subtree root section,\n",
        "    using a recursive hoc function,\n",
        "\n",
        "    returns the lowest impedance in Ohms\n",
        "    '''\n",
        "    # returns [lowest subtree transfer impedance in Mohms, transfer phase]\n",
        "    lowest_impedance = h.lowest_impedance_recursive(subtree_root_ref, imp_obj)\n",
        "    # impedance saved as a complex number after converting Mohms to ohms\n",
        "    curr_lowest_subtree_imp = cmath.rect(lowest_impedance.x[0] * 1000000, lowest_impedance.x[1])\n",
        "    return curr_lowest_subtree_imp\n",
        "\n",
        "\n",
        "def compute_zl_polar(Z0, L, q):\n",
        "    '''\n",
        "    given Z0 , L and q computes the polar represntation of ZL (equation 2.9 in Gals thesis)\n",
        "    '''\n",
        "    ZL = Z0 * 1.0 / cmath.cosh(q * L)\n",
        "    ZL = cmath.polar(ZL)\n",
        "    return ZL\n",
        "\n",
        "\n",
        "def find_best_real_L(Z0, ZL_goal, q, max_L=10.0, max_depth=50):\n",
        "    '''finds the best real L\n",
        "\n",
        "    s.t. the modulus part of the impedance of ZL in eq 2.9 will be correct\n",
        "    Since the modulus is a decreasing function of L, it is easy to find it using binary search.\n",
        "    '''\n",
        "    min_L = 0.0\n",
        "    current_L = (min_L + max_L) / 2.0\n",
        "    ZL_goal_A = cmath.polar(ZL_goal)[0]\n",
        "\n",
        "    for _ in range(max_depth):\n",
        "        Z_current_L_A = compute_zl_polar(Z0, current_L, q)[0]\n",
        "        if abs(ZL_goal_A - Z_current_L_A) <= 0.001:  # Z are in Ohms , normal values are >10^6\n",
        "            break\n",
        "        elif ZL_goal_A > Z_current_L_A:\n",
        "            current_L, max_L = (min_L + current_L) / 2.0, current_L\n",
        "        else:\n",
        "            current_L, min_L = (max_L + current_L) / 2.0, current_L\n",
        "    else:\n",
        "        logger.info(\"The difference between L and the goal L is larger than 0.001\")\n",
        "    return current_L\n",
        "\n",
        "\n",
        "def compute_zx_polar(Z0, L, q, x):\n",
        "    '''computes the polar represntation of Zx (equation 2.8 in Gals thesis)\n",
        "    '''\n",
        "    ZX = Z0 * cmath.cosh(q * (L - x)) / cmath.cosh(q * L)\n",
        "    ZX = cmath.polar(ZX)\n",
        "    return ZX\n",
        "\n",
        "\n",
        "def find_best_real_X(Z0, ZX_goal, q, L, max_depth=50):\n",
        "    '''finds the best location of a synapse (X)\n",
        "\n",
        "    s.t. the modulus part of the impedance of ZX in eq 2.8 will be correct.\n",
        "    Since the modulus is a decreasing function of L, it is easy to find it using binary search.\n",
        "    '''\n",
        "    min_x, max_x = 0.0, L\n",
        "    current_x = (min_x + max_x) / 2.0\n",
        "\n",
        "    ZX_goal = cmath.polar(ZX_goal)[0]\n",
        "\n",
        "    for _ in range(max_depth):\n",
        "        Z_current_X_A = compute_zx_polar(Z0, L, q, current_x)[0]\n",
        "\n",
        "        if abs(ZX_goal - Z_current_X_A) <= 0.001:\n",
        "            break\n",
        "        elif ZX_goal > Z_current_X_A:\n",
        "            current_x, max_x = (min_x + current_x) / 2.0, current_x\n",
        "        else:\n",
        "            current_x, min_x = (max_x + current_x) / 2.0, current_x\n",
        "    else:\n",
        "        logger.info(\"The difference between X and the goal X is larger than 0.001\")\n",
        "\n",
        "    return current_x\n",
        "\n",
        "\n",
        "def find_subtree_new_electrotonic_length(root_input_impedance, lowest_subtree_impedance, q):\n",
        "    ''' finds the subtree's reduced cable's electrotonic length\n",
        "\n",
        "    based on the following equation:\n",
        "    lowest_subtree_impedance = subtree_root_input_impedance/cosh(q*L)\n",
        "    according to the given complex impedance values\n",
        "    '''\n",
        "\n",
        "    # this equation could be solved analytically using:\n",
        "    # L = 1/q * arcosh(subtree_root_input_impedance/lowest_subtree_impedance),\n",
        "    # But since L in this equation is complex number and we chose to focus on\n",
        "    # finding the correct attenuation\n",
        "    # we decided to search the L that will result with correct attenuation from\n",
        "    # the tip of the dendrite to the soma.\n",
        "    # We chose to use only real L (without a complex part)\n",
        "\n",
        "    L = find_best_real_L(root_input_impedance, lowest_subtree_impedance, q)\n",
        "    return L\n",
        "\n",
        "\n",
        "def _find_subtree_new_diam_in_cm(root_input_impedance, electrotonic_length_as_complex, rm, ra, q):\n",
        "    '''finds the subtree's new cable's diameter (in cm)\n",
        "\n",
        "    according to the given complex input impedance at the segment in the\n",
        "    original subtree that is closest to the soma (the tip), and the given cable\n",
        "    electrotonic length,\n",
        "\n",
        "    with the following equation:\n",
        "    d (in cm) = (2/PI * (sqrt(RM*RA)/(q*subtree_root_input_impedance)) *\n",
        "                 (coth(q * NewCableElectrotonicLength)) )^(2/3)\n",
        "    derived from Rall's cable theory for dendrites (Gal Eliraz)\n",
        "    '''\n",
        "\n",
        "    diam_in_cm = (2.0 / math.pi *\n",
        "                  (math.sqrt(rm * ra) / (q * root_input_impedance)) *\n",
        "                  (1 / cmath.tanh(q * electrotonic_length_as_complex))  # coth = 1/tanh\n",
        "                  ) ** (2.0 / 3)\n",
        "\n",
        "    '''\n",
        "    # for debugging inaccuracies:\n",
        "    if diam_in_cm.imag != 0:\n",
        "        if abs(diam_in_cm.imag) > 0.03:\n",
        "        print \"PROBLEM - DIAM HAS SUBSTANTIAL IMAGINARY PART\"\n",
        "        print \"\\n\"\n",
        "    '''\n",
        "\n",
        "    # the radius of the complex number received from the equation\n",
        "    new_subtree_dend_diam_in_cm = cmath.polar(diam_in_cm)[0]\n",
        "    return new_subtree_dend_diam_in_cm\n",
        "\n",
        "\n",
        "def find_space_const_in_cm(diameter, rm, ra):\n",
        "    ''' returns space constant (lambda) in cm, according to: space_const = sqrt(rm/(ri+r0)) '''\n",
        "    # rm = Rm/(PI * diam), diam is in cm and Rm is in ohm * cm^2\n",
        "    rm = float(rm) / (math.pi * diameter)\n",
        "    # ri = 4*Ra/ (PI * diam^2), diam is in cm and Ra is in ohm * cm\n",
        "    ri = float(4 * ra) / (math.pi * (diameter**2))\n",
        "    space_const = math.sqrt(rm / ri)  # r0 is negligible\n",
        "    return space_const\n",
        "\n",
        "\n",
        "def reduce_subtree(subtree_root, frequency):\n",
        "    '''Reduces the subtree  from the original_cell into one single section (cable).\n",
        "\n",
        "    The reduction is done by finding the length and diameter of the cable (a\n",
        "    single solution) that preserves the subtree's input impedance at the\n",
        "    somatic end, and the transfer impedance in the subtree from the distal end\n",
        "    to the proximal somatic end (between the new cable's two tips).\n",
        "    '''\n",
        "\n",
        "    subtree_root_ref = h.SectionRef(sec=subtree_root)\n",
        "    cm, rm, ra, e_pas, q = _get_subtree_biophysical_properties(subtree_root_ref, frequency)\n",
        "\n",
        "    # finds the subtree's input impedance (at the somatic-proximal end of the\n",
        "    # subtree root section) and the lowest transfer impedance in the subtree in\n",
        "    # relation to the somatic-proximal end (see more in Readme on NeuroReduce)\n",
        "    imp_obj, root_input_impedance = measure_input_impedance_of_subtree(subtree_root, frequency)\n",
        "\n",
        "    # in Ohms (a complex number)\n",
        "    curr_lowest_subtree_imp = find_lowest_subtree_impedance(subtree_root_ref, imp_obj)\n",
        "\n",
        "    # reducing the whole subtree into one section:\n",
        "    # L = 1/q * arcosh(ZtreeIn(f)/min(ZtreeX,0(f)),\n",
        "    # d = ( (2/pi * (sqrt(Rm*Ra)/q*ZtreeIn(f)) * coth(qL) )^(2/3) - from Gal Eliraz's thesis 1999\n",
        "    new_cable_electrotonic_length = find_subtree_new_electrotonic_length(root_input_impedance,\n",
        "                                                                         curr_lowest_subtree_imp,\n",
        "                                                                         q)\n",
        "    cable_electrotonic_length_as_complex = complex(new_cable_electrotonic_length, 0)\n",
        "    new_cable_diameter_in_cm = _find_subtree_new_diam_in_cm(root_input_impedance,\n",
        "                                                            cable_electrotonic_length_as_complex,\n",
        "                                                            rm,\n",
        "                                                            ra,\n",
        "                                                            q)\n",
        "    new_cable_diameter = new_cable_diameter_in_cm * 10000   # in microns\n",
        "\n",
        "    # calculating the space constant, in order to find the cylinder's length:\n",
        "    # space_const = sqrt(rm/(ri+r0))\n",
        "    curr_space_const_in_cm = find_space_const_in_cm(new_cable_diameter_in_cm,\n",
        "                                                    rm,\n",
        "                                                    ra)\n",
        "    curr_space_const_in_micron = 10000 * curr_space_const_in_cm\n",
        "    new_cable_length = curr_space_const_in_micron * new_cable_electrotonic_length  # in microns\n",
        "\n",
        "    return CableParams(length=new_cable_length,\n",
        "                       diam=new_cable_diameter,\n",
        "                       space_const=curr_space_const_in_micron,\n",
        "                       cm=cm,\n",
        "                       rm=rm,\n",
        "                       ra=ra,\n",
        "                       e_pas=e_pas,\n",
        "                       electrotonic_length=new_cable_electrotonic_length)\n",
        "\n",
        "\n",
        "def find_merged_loc(cable_nseg, relative_loc):\n",
        "    '''\n",
        "    Returns a synapse's merged relative location (x) on the cable, according to\n",
        "    its given relative location on the cable and the given number of segments\n",
        "    in the cable.\n",
        "\n",
        "    The merged location is the relative location of the middle of the segment\n",
        "    the synapse is in (or 0 or 1 if it is at one of the tips of the cable).\n",
        "    '''\n",
        "\n",
        "    if relative_loc in (0, 1):\n",
        "        return relative_loc\n",
        "\n",
        "    # finds the segment that the synapse is in, according to its relative\n",
        "    # location and the num of segments in the cable (1 through nseg)\n",
        "    mapped_segment_for_curr_syn = int(relative_loc * cable_nseg) + 1\n",
        "\n",
        "    # location of middle of segment = the average between relative location of\n",
        "    # end of segment and relative location of beginning of segment\n",
        "    return ((float(mapped_segment_for_curr_syn) / cable_nseg) +\n",
        "            (float(mapped_segment_for_curr_syn - 1) / cable_nseg)) / 2\n",
        "\n",
        "\n",
        "def measure_input_impedance_of_subtree(subtree_root_section, frequency):\n",
        "    '''measures the input impedance of the subtree with the given root section\n",
        "\n",
        "    (at the \"0\" tip, the soma-proximal end),\n",
        "    returns the Impedance hoc object and the input impedance as a complex value\n",
        "    '''\n",
        "\n",
        "    imp_obj = h.Impedance()\n",
        "    CLOSE_TO_SOMA_EDGE = 0\n",
        "    # sets origin for impedance calculations (soma-proximal end of root section)\n",
        "    imp_obj.loc(CLOSE_TO_SOMA_EDGE, sec=subtree_root_section)\n",
        "\n",
        "    # computes transfer impedance from every segment in the model in relation\n",
        "    # to the origin location above\n",
        "    imp_obj.compute(frequency + 1 / 9e9, 0)\n",
        "\n",
        "    # in Ohms (impedance measured at soma-proximal end of root section)\n",
        "    root_input_impedance = imp_obj.input(CLOSE_TO_SOMA_EDGE, sec=subtree_root_section) * 1000000\n",
        "    root_input_phase = imp_obj.input_phase(CLOSE_TO_SOMA_EDGE, sec=subtree_root_section)\n",
        "    # creates a complex impedance value out of the given polar coordinates\n",
        "    root_input_impedance = cmath.rect(root_input_impedance, root_input_phase)\n",
        "    return imp_obj, root_input_impedance\n",
        "\n",
        "\n",
        "def reduce_synapse(cell_instance,\n",
        "                   synapse_location,\n",
        "                   on_basal,\n",
        "                   imp_obj,\n",
        "                   root_input_impedance,\n",
        "                   new_cable_electrotonic_length,\n",
        "                   q_subtree):\n",
        "    '''\n",
        "    Receives an instance of a cell, the location (section + relative\n",
        "    location(x)) of a synapse to be reduced, a boolean on_basal that is True if\n",
        "    the synapse is on a basal subtree, the number of segments in the reduced\n",
        "    cable that this synapse is in, an Impedance calculating Hoc object, the\n",
        "    input impedance at the root of this subtree, and the electrotonic length of\n",
        "    the reduced cable that represents the current subtree\n",
        "    (as a real and as a complex number) -\n",
        "    and maps the given synapse to its new location on the reduced cable\n",
        "    according to the NeuroReduce algorithm.  Returns the new \"post-merging\"\n",
        "    relative location of the synapse on the reduced cable (x, 0<=x<=1), that\n",
        "    represents the middle of the segment that this synapse is located at in the\n",
        "    new reduced cable.\n",
        "    '''\n",
        "    # measures the original transfer impedance from the synapse to the\n",
        "    # somatic-proximal end in the subtree root section\n",
        "    if not on_basal:  # apical subtree\n",
        "        section = cell_instance.apic[synapse_location.section_num]\n",
        "    else:             # basal subtree\n",
        "        section = cell_instance.dend[synapse_location.section_num]\n",
        "\n",
        "    with push_section(section):\n",
        "        orig_transfer_imp = imp_obj.transfer(synapse_location.x) * 1000000  # ohms\n",
        "        orig_transfer_phase = imp_obj.transfer_phase(synapse_location.x)\n",
        "        # creates a complex Impedance value with the given polar coordinates\n",
        "        orig_synapse_transfer_impedance = cmath.rect(orig_transfer_imp, orig_transfer_phase)\n",
        "\n",
        "    # synapse location could be calculated using:\n",
        "    # X = L - (1/q) * arcosh( (Zx,0(f) / ZtreeIn(f)) * cosh(q*L) ),\n",
        "    # derived from Rall's cable theory for dendrites (Gal Eliraz)\n",
        "    # but we chose to find the X that will give the correct modulus. See comment about L values\n",
        "\n",
        "    synapse_new_electrotonic_location = find_best_real_X(root_input_impedance,\n",
        "                                                         orig_synapse_transfer_impedance,\n",
        "                                                         q_subtree,\n",
        "                                                         new_cable_electrotonic_length)\n",
        "    new_relative_loc_in_section = (float(synapse_new_electrotonic_location) /\n",
        "                                   new_cable_electrotonic_length)\n",
        "\n",
        "    if new_relative_loc_in_section > 1:  # PATCH\n",
        "        new_relative_loc_in_section = 0.999999\n",
        "\n",
        "    return new_relative_loc_in_section"
      ],
      "metadata": {
        "id": "ptLTmkiFUzoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Custom Functions"
      ],
      "metadata": {
        "id": "HEkavOdOTXGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complex Cell"
      ],
      "metadata": {
        "id": "rGlXTKXWRpqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create Cell"
      ],
      "metadata": {
        "id": "5sEq2ENSVVbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Complex Cell\n",
        "# #Create a L5_PC model\n",
        "# h.load_file('L5PCbiophys3.hoc')\n",
        "# h.load_file(\"import3d.hoc\")\n",
        "# h.load_file('L5PCtemplate.hoc')\n",
        "# complex_cell = h.L5PCtemplate('cell1.asc')\n",
        "# h.celsius = 37\n",
        "# h.v_init = complex_cell.soma[0].e_pas\n",
        "\n",
        "# create a simple cell\n",
        "soma = h.Section(name='soma')\n",
        "soma.L = 20\n",
        "soma.diam = 20\n",
        "soma.insert('hh')"
      ],
      "metadata": {
        "id": "Dk4VEyMmRGL0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16017b3-84b6-430e-9a32-8ed30e4b497f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "soma"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Add synapses to the cell"
      ],
      "metadata": {
        "id": "7qCm8VkoVYPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #Add synapses to the model\n",
        "# synapses_list, netstims_list, netcons_list, randoms_list = [], [], [] ,[]\n",
        "\n",
        "# all_segments = [i for j in map(list,list(complex_cell.apical)) for i in j] + [i for j in map(list,list(complex_cell.basal)) for i in j]\n",
        "# len_per_segment = np.array([seg.sec.L/seg.sec.nseg for seg in all_segments])\n",
        "# rnd = np.random.RandomState(10)\n",
        "# for i in range(10000):\n",
        "#     seg_for_synapse = rnd.choice(all_segments,   p=len_per_segment/sum(len_per_segment)) #choose a random segment with probability based on the length of segment\n",
        "#     synapses_list.append(h.Exp2Syn(seg_for_synapse))\n",
        "#     if rnd.uniform()<0.85: # 85% synapses are excitatory\n",
        "#         e_syn, tau1, tau2, spike_interval, syn_weight = 0, 0.3, 1.8,  1000/2.5, 0.0016\n",
        "#     else: #inhibitory case\n",
        "#         e_syn, tau1, tau2, spike_interval, syn_weight = -86, 1,   8,   1000/15.0, 0.0008\n",
        "#     #set synaptic varibales\n",
        "#     synapses_list[i].e, synapses_list[i].tau1, synapses_list[i].tau2 = e_syn, tau1, tau2\n",
        "#     #set netstim variables\n",
        "#     netstims_list.append(h.NetStim())\n",
        "#     netstims_list[i].interval, netstims_list[i].number, netstims_list[i].start, netstims_list[i].noise = spike_interval, 9e9, 100, 1\n",
        "#     #set random\n",
        "#     randoms_list.append(h.Random())\n",
        "#     randoms_list[i].Random123(i)\n",
        "#     randoms_list[i].negexp(1)\n",
        "#     netstims_list[i].noiseFromRandom(randoms_list[i])       \n",
        "#     #set netcon varibales \n",
        "#     netcons_list.append(h.NetCon(netstims_list[i], synapses_list[i] ))\n",
        "#     netcons_list[i].delay, netcons_list[i].weight[0] = 0, syn_weight"
      ],
      "metadata": {
        "id": "w8TBT4TEVbd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "671e6222-b1bb-4f81-f741-1a18c098824c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-87e13a8f287b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msynapses_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetstims_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetcons_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandoms_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mall_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplex_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mlen_per_segment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnseg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_segments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mrnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'complex_cell' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Simulate the complex cell"
      ],
      "metadata": {
        "id": "8oUEKDnYVezS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soma_v = h.Vector()\n",
        "soma_v.record(complex_cell.soma[0](0.5)._ref_v)\n",
        "\n",
        "time_v = h.Vector()\n",
        "time_v.record(h._ref_t)\n",
        "\n",
        "h.tstop = 1000\n",
        "st = time.time()\n",
        "h.run()\n",
        "print('complex cell simulation time {:.4f}'.format(time.time()-st))\n",
        "complex_cell_v = list(soma_v)"
      ],
      "metadata": {
        "id": "cTce_JItVhP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Plot original, complex morphology"
      ],
      "metadata": {
        "id": "L9Mc-PmBRtUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot original, complex morphology"
      ],
      "metadata": {
        "id": "dg67B2o0QLNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Core Reduced Cell"
      ],
      "metadata": {
        "id": "IIp4ZFiLR1Jx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reduction Method"
      ],
      "metadata": {
        "id": "89S2ukH8R-HZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduction Method\n",
        "#apply Neuron_Reduce to simplify the cell\n",
        "reduced_cell, synapses_list, netcons_list, txt = subtree_reductor(complex_cell, synapses_list, netcons_list, reduction_frequency=0,return_seg_to_seg=True)\n",
        "for r in randoms_list:r.seq(1) #reset random\n",
        "\n",
        "\n",
        "#Running the simulation again but now on the reduced cell\n",
        "st = time.time()\n",
        "h.run()\n",
        "print('reduced cell simulation time {:.4f}'.format(time.time()-st))\n",
        "reduced_celll_v = list(soma_v)\n",
        "\n",
        "#plotting the results\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(time_v, complex_cell_v, label='complex cell')\n",
        "plt.plot(time_v, reduced_celll_v,  label='reduced cell')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b3gS8sA8RDvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot reduced, cable morphology"
      ],
      "metadata": {
        "id": "DCWfgE7RSADU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yXSkT_0PtUf"
      },
      "outputs": [],
      "source": [
        "# Plot reduced,  cable morphology"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Branching Reduced Cell"
      ],
      "metadata": {
        "id": "m4IOkN0TSHNh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Expansion Method"
      ],
      "metadata": {
        "id": "-q6c2m26SM6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Expansion Method"
      ],
      "metadata": {
        "id": "bA5shkdQRAwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Simulate the branching Reduced Cell"
      ],
      "metadata": {
        "id": "7TCIvUIWV_4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Plot Branching Reduced Cell"
      ],
      "metadata": {
        "id": "rFU3oV5ASOp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot reduced, dendritic morphology"
      ],
      "metadata": {
        "id": "Ql3YE2c5QxlA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}