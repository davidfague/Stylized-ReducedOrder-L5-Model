{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidfague/Stylized-ReducedOrder-L5-Model/blob/main/SROC_Passive_Properties.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xkx-mbZKD8c2"
      },
      "source": [
        "#### Neuron Initialization\n",
        "Import modules and setup simulation parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqK980HfECA5",
        "outputId": "0f625b24-3c39-41b3-9821-eba420927abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting neuron\n",
            "  Downloading NEURON-8.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.7/dist-packages (from neuron) (1.21.6)\n",
            "Installing collected packages: neuron\n",
            "Successfully installed neuron-8.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install neuron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t4aHlZPNEvm4",
        "outputId": "95b814b4-0e99-4946-86be-04e1fce3a107",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R6h5ZsGjs5GO",
        "outputId": "92a26ed4-0473-4a2c-d8f7-8941d51337e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Stylized-Cell-model\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Stylized-Cell-model/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9zVOUnOV9WxH"
      },
      "outputs": [],
      "source": [
        "from neuron import h,nrn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import lognorm\n",
        "import time as time\n",
        "import os\n",
        "from typing import Optional, List, Tuple, Union\n",
        "from functools import partial\n",
        "import scipy.signal as ss\n",
        "import scipy.stats as st\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KpT_pFwdD8c9"
      },
      "outputs": [],
      "source": [
        "from stylized_module.stylized_cell import Stylized_Cell\n",
        "from stylized_module.ecp import EcpMod, newposition\n",
        "from stylized_module.recorder import Recorder\n",
        "from stylized_module.point_current import Point_current\n",
        "\n",
        "# from inputs_module.build_network import _make_rasters,_gen_group_spikes,_gen_exc_spikes,_gen_inh_spikes\n",
        "# from inputs_module.clustering import FunctionalGroup\n",
        "# #from inputs_module.modulate_exc import \n",
        "# from inputs_module.raster_maker import SonataWriter,make_noise,shift_exc_noise,make_save_spikes,minmax\n",
        "# #from inputs_module.synapses import \n",
        "mechanisms_path = 'mechanisms'  # need to compile the folder first\n",
        "geometry_file = 'geom_parameters.csv'\n",
        "tstop = 1500  # ms simulation duration\n",
        "dt = 0.1  # ms. does not allow change\n",
        "\n",
        "h.load_file('stdrun.hoc')\n",
        "#h.nrn_load_dll(os.path.join(mechanisms_path,'nrnmech.dll'))  # running this line more than once might crash the kernel\n",
        "h.nrn_load_dll(os.path.join(mechanisms_path,'x86_64/.libs/libnrnmech.so'))  # use this line instead in Linux\n",
        "geo_standard = pd.read_csv(geometry_file,index_col='id')\n",
        "h.tstop = tstop\n",
        "h.dt = dt\n",
        "h.steps_per_ms = 1/h.dt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZix4H7RZDfG"
      },
      "source": [
        "##Extra Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "urpIM_WeRGOq"
      },
      "outputs": [],
      "source": [
        "#pick a random seed to initalize random values\n",
        "import random\n",
        "random.seed(427)\n",
        "pi=np.pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zLrDO_nlrxz1"
      },
      "outputs": [],
      "source": [
        "# def lognormal(m, s):\n",
        "#         mean = np.log(m) - 0.5 * np.log((s/m)**2+1)\n",
        "#         std = np.sqrt(np.log((s/m)**2 + 1))\n",
        "#         #import pdb; pdb.set_trace()\n",
        "#         return max(np.random.lognormal(mean, std, 1), 0.00000001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EoJyg_fv7yGM",
        "outputId": "6a0d7383-1be8-4ad3-c9b6-f6fc52565e9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-2.299528896659566\n",
            "1.1748114608101725\n"
          ]
        }
      ],
      "source": [
        "#get underlying normal distribution parameters from lognormal distribution parameters\n",
        "m=.2\n",
        "s=0.345\n",
        "mean = np.log(m) - 0.5 * np.log((s/m)**2+1)\n",
        "std = np.sqrt(np.log((s/m)**2 + 1))\n",
        "print(mean)\n",
        "print(std)\n",
        "\n",
        "#Additional functions\n",
        "def normalize(x):\n",
        "    \"\"\"normalizes the given array\"\"\"\n",
        "    return (x - np.min(x))/(np.max(x)-np.min(x))\n",
        "\n",
        "def make_noise(num_traces=100,num_samples=4999):\n",
        "    \"\"\"Creates a noise trace used in generating spike rasters.\n",
        "    Parameters\n",
        "    ----------\n",
        "    num_traces : int, optionalj\n",
        "        number of noise traces to create (first dimension), by default 100\n",
        "    num_samples : int, optional\n",
        "        length of the trace (second dimension), by default 4999\n",
        "    Returns\n",
        "    -------\n",
        "    np.array\n",
        "        noise trace\n",
        "    \"\"\"    \n",
        "    B = [0.049922035, -0.095993537, 0.050612699, -0.004408786]\n",
        "    A = [1, -2.494956002,   2.017265875,  -0.522189400]\n",
        "    invfn = np.zeros((num_traces,num_samples))\n",
        "    for i in np.arange(0,num_traces):\n",
        "        wn = np.random.normal(loc=1,\n",
        "        scale=0.5,size=num_samples+2000)\n",
        "        invfn[i,:] = normalize(ss.lfilter(B, A, wn)[2000:])+0.5                             # Create '1/f' Noise\n",
        "    return invfn\n",
        "def shift_exc_noise(ts, nid, seconds, time_shift=4):\n",
        "    \"\"\"Creates a shifted, min-max normalized average traces of the given spike raster.\n",
        "    Parameters\n",
        "    ----------\n",
        "    ts : list\n",
        "        times (float) where spikes occur\n",
        "    nid : int\n",
        "        node id associated with each spike\n",
        "    seconds : float\n",
        "        length of the raster in seconds\n",
        "    time_shift : int, optional\n",
        "        how many ms to shift the average trace by, by default 4\n",
        "    Returns\n",
        "    -------\n",
        "    [type]\n",
        "        [description]\n",
        "    \"\"\"    \n",
        "    h = np.histogram(ts,bins=np.arange(0,seconds*1000,1))\n",
        "\n",
        "    fr_prof = h[0]/(0.001*(np.max(nid)+1))\n",
        "    wrap = fr_prof[-4:]\n",
        "    fr_prof[4:] = fr_prof[0:-4]\n",
        "    fr_prof[0:4] = wrap\n",
        "\n",
        "    fr_prof = normalize(fr_prof)+0.5\n",
        "    return fr_prof"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fakn5zb9XH19"
      },
      "outputs": [],
      "source": [
        "class SonataWriter:\n",
        "    \"\"\"Class used to dynamically writing spike rasters to an h5 file.\n",
        "    Attributes\n",
        "    ----------\n",
        "    file : h5py.File\n",
        "        file object being worked on\n",
        "    group : h5py.Group\n",
        "        gropu where the datasets reside\n",
        "    datasets : dict\n",
        "        datasets that are saved to the file\n",
        "    Methods\n",
        "    -------\n",
        "    append_ds(vals, ds)\n",
        "        appends the given values to the end of the given dataset\n",
        "    append_repeat(ds, val, N)\n",
        "        appends the given value N times to the end of the given dataset\n",
        "    close()\n",
        "        close the h5py file\n",
        "    \"\"\"\n",
        "    def __init__(self, f_name, groups, datasets, types):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        f_name : str\n",
        "            name of file locationmake\n",
        "        groups : list\n",
        "            list of group names (str) that are layered into the h5py file\n",
        "            in the order given.\n",
        "        datasets : list\n",
        "            list of dataset names (str)\n",
        "        types : list\n",
        "            list of data types that corresponds to the datasets list\n",
        "        \"\"\"        \n",
        "        self.file = h5py.File(f_name, 'w')\n",
        "\n",
        "        self.group = self.file\n",
        "        for group in groups:\n",
        "            self.group = self.group.create_group(group)\n",
        "\n",
        "        self.datasets = {}\n",
        "        for i, ds in enumerate(datasets):\n",
        "            self.datasets[ds] = self.group.create_dataset(ds, data=[], dtype=types[i], chunks=True, maxshape=(None,))\n",
        "\n",
        "    def append_ds(self, vals, ds):\n",
        "        \"\"\"appends the given values to the end of the given dataset\n",
        "        Parameters\n",
        "        ----------\n",
        "        vals : list\n",
        "            list of values to be appended to the dataset\n",
        "        ds : str\n",
        "            key of the dataset to append to\n",
        "        \"\"\"        \n",
        "        length = len(self.datasets[ds])\n",
        "        self.datasets[ds].resize((length + len(vals), ))\n",
        "        self.datasets[ds][length:] = vals\n",
        "\n",
        "    def append_repeat(self, ds, val, N):\n",
        "        \"\"\"appends the given value N times to the end of the given dataset\n",
        "        Parameters\n",
        "        ----------\n",
        "        ds : str\n",
        "            key of the dataset to append to\n",
        "        val : [type]\n",
        "            value to be appended N times\n",
        "        N : int\n",
        "            number of vals to append to the dataset\n",
        "        \"\"\"        \n",
        "        self.append_ds([val for i in range(N)], ds)\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Closes the h5py File\n",
        "        \"\"\"        \n",
        "        self.file.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hI4TL9ZD8c_"
      },
      "source": [
        "##Define cell model and simulation model. Edit method \"set_channels\" to design biophysical properties."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UhthwMDQD8dA"
      },
      "outputs": [],
      "source": [
        "class Cell(Stylized_Cell):\n",
        "    \"\"\"Define single cell model using parent class Stylized_Cell\"\"\"\n",
        "    def __init__(self,geometry=None,biophys=None,dL=5,vrest=-72.0): #-90? # dL=30 originally\n",
        "        \"\"\"\n",
        "        Initialize cell model\n",
        "        geometry: pandas dataframe of cell morphology properties\n",
        "        biophys: vector of biophysical parameters corresponding to \"biophys_entries\". Use -1 for default value.\n",
        "        dL: maximum segment length\n",
        "        vrest: reversal potential for leak channels\n",
        "        \"\"\"\n",
        "        self.biophys = biophys\n",
        "        super().__init__(geometry,dL,vrest)\n",
        "        self.record_soma_v() # uncomment this if want to record soma voltage\n",
        "        self.syn_dist_list = []\n",
        "        self.gmax_list = []\n",
        "        self.P_0_list = []\n",
        "        self.synapse_sec_list = []\n",
        "    \n",
        "    def set_channels(self):\n",
        "        \"\"\"Define biophysical properties, insert channels\"\"\"\n",
        "        self.define_biophys_entries()\n",
        "        # common parameters\n",
        "        for sec in self.all:\n",
        "            sec.cm = 2.0\n",
        "            sec.Ra = 100\n",
        "            sec.insert('pas')\n",
        "            sec.e_pas = self._vrest\n",
        "        # fixed parameters\n",
        "        soma = self.soma\n",
        "        soma.cm = 1.0           # Originally 1 \n",
        "        soma.insert('NaTa_t')  # Sodium channel\n",
        "        soma.insert('SKv3_1')  # Potassium channel\n",
        "        soma.insert('Ca_HVA')\n",
        "        soma.insert('Ca_LVAst')\n",
        "        soma.insert('CaDynamics_E2')\n",
        "        soma.insert('Ih')\n",
        "        soma.insert('SK_E2')\n",
        "        soma.insert('K_Tst')\n",
        "        soma.insert('K_Pst')\n",
        "        soma.insert('Nap_Et2')\n",
        "        soma.ena = 50\n",
        "        soma.ek = -85\n",
        "        \n",
        "\n",
        "        for isec in self.grp_ids[1]:        #prox,mid,dist basal; proxtrunk; oblique\n",
        "            sec = self.get_sec_by_id(isec) \n",
        "            sec.insert('NaTa_t')\n",
        "            sec.insert('SKv3_1')\n",
        "            sec.insert('Ca_HVA')\n",
        "            sec.insert('Ca_LVAst')\n",
        "            sec.insert('Im')\n",
        "            sec.insert('CaDynamics_E2')\n",
        "            sec.insert('Ih')\n",
        "            sec.insert('SK_E2')\n",
        "            sec.ena = 50\n",
        "            sec.ek = -85\n",
        "\n",
        "        for isec in self.grp_ids[2]:\n",
        "            sec = self.get_sec_by_id(isec)  # Mid Trunk\n",
        "            sec.insert('NaTa_t')\n",
        "            sec.insert('SKv3_1')\n",
        "            sec.insert('Ca_HVA')\n",
        "            sec.insert('Ca_LVAst')\n",
        "            sec.insert('Im')\n",
        "            sec.insert('CaDynamics_E2')\n",
        "            sec.insert('Ih')\n",
        "            sec.insert('SK_E2')\n",
        "            sec.ena = 50\n",
        "            sec.ek = -85\n",
        "\n",
        "\n",
        "        for isec in self.grp_ids[3]:\n",
        "            sec = self.get_sec_by_id(isec)  # Distal Trunk\n",
        "            sec.insert('NaTa_t')\n",
        "            sec.insert('SKv3_1')\n",
        "            sec.insert('Ca_HVA')\n",
        "            sec.insert('Ca_LVAst')\n",
        "            sec.insert('Im')\n",
        "            sec.insert('CaDynamics_E2')\n",
        "            sec.insert('Ih')\n",
        "            sec.insert('SK_E2')\n",
        "            sec.ena = 50\n",
        "            sec.ek = -85\n",
        "\n",
        "        for isec in self.grp_ids[4]:\n",
        "            sec = self.get_sec_by_id(isec)  # Tuft dendrites\n",
        "            sec.insert('NaTa_t')\n",
        "            sec.insert('SKv3_1')\n",
        "            sec.insert('Ca_HVA')\n",
        "            sec.insert('Ca_LVAst')\n",
        "            sec.insert('Im')\n",
        "            sec.insert('CaDynamics_E2')\n",
        "            sec.insert('Ih')\n",
        "            sec.insert('SK_E2')\n",
        "            sec.ena = 50\n",
        "            sec.ek = -85\n",
        "\n",
        "\n",
        "        for isec in self.grp_ids[5]:\n",
        "            sec = self.get_sec_by_id(isec)  # axon\n",
        "            sec.cm = 2.0\n",
        "            sec.insert('NaTa_t')\n",
        "            sec.insert('SKv3_1')\n",
        "            sec.insert('Ca_HVA')\n",
        "            sec.insert('Ca_LVAst')\n",
        "            sec.insert('Im')\n",
        "            sec.insert('CaDynamics_E2')\n",
        "            sec.insert('Ih')\n",
        "            sec.insert('SK_E2')\n",
        "            sec.insert('K_Tst')\n",
        "            sec.insert('K_Pst')\n",
        "            sec.insert('Nap_Et2')\n",
        "            sec.ena = 50\n",
        "            sec.ek = -85\n",
        "\t\t        \n",
        "        for isec in self.grp_ids[6]:\n",
        "            sec = self.get_sec_by_id(isec)  # inactive dendrites\n",
        "            sec.cm = 3.0\n",
        "            sec.insert('NaTa_t')\n",
        "            sec.insert('SKv3_1')\n",
        "            sec.insert('Ca_HVA')\n",
        "            sec.insert('Ca_LVAst')\n",
        "            sec.insert('CaDynamics_E2')\n",
        "            sec.insert('Ih')\n",
        "            sec.ena = 50\n",
        "            sec.ek = -85\n",
        "\n",
        "        # variable parameters\n",
        "        for i,entry in enumerate(self.biophys_entries):\n",
        "            for sec in self.get_sec_by_id(self.grp_ids[entry[0]]):\n",
        "                setattr(sec,entry[1],self.biophys[i])\n",
        "        h.v_init = self._vrest\n",
        "    \n",
        "\n",
        "    def define_biophys_entries(self):\n",
        "        \"\"\"\n",
        "        Define list of entries of biophysical parameters.\n",
        "        Each entry is a pair of group id and parameter reference string.\n",
        "        Define default values and set parameters in \"biophys\".\n",
        "        \"\"\"\n",
        "        self.grp_sec_type_ids = [ # select section id's for each group\n",
        "                                 [0], #soma\n",
        "                                 [1,2,3,4,5], #basal group: prox,mid,dist basal; proxtrunk; oblique\n",
        "                                 [6], #mid trunk\n",
        "                                 [7], #nexus: distal trunk\n",
        "                                 [8,9,10], #tuft: prox,mid,dist tuft\n",
        "                                 [11], #axon\n",
        "                                 [12] #passive basal dendrites\n",
        "                                 ]\n",
        "        self.grp_ids = []  # get indices of sections for each group\n",
        "        for ids in self.grp_sec_type_ids:\n",
        "            secs = []\n",
        "            for i in ids:\n",
        "                secs.extend(self.sec_id_lookup[i])\n",
        "            self.grp_ids.append(secs)\n",
        "        self.biophys_entries = [\n",
        "            (0,'g_pas'),(1,'g_pas'),(2,'g_pas'),(3,'g_pas'),(4,'g_pas'),(5,'g_pas'),(6,'g_pas'),  # g_pas of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "            (0,'gNaTa_tbar_NaTa_t'),(1,'gNaTa_tbar_NaTa_t'),(2,'gNaTa_tbar_NaTa_t'),(3,'gNaTa_tbar_NaTa_t'),(4,'gNaTa_tbar_NaTa_t'),(5,'gNaTa_tbar_NaTa_t'),(6,'gNaTa_tbar_NaTa_t'),  # gNaTa_t of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "            (0,'gSKv3_1bar_SKv3_1'),(1,'gSKv3_1bar_SKv3_1'),(2,'gSKv3_1bar_SKv3_1'),(3,'gSKv3_1bar_SKv3_1'),(4,'gSKv3_1bar_SKv3_1'),(5,'gSKv3_1bar_SKv3_1'),(6,'gSKv3_1bar_SKv3_1'),  # gSKv3_1 of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "            (0, 'gCa_HVAbar_Ca_HVA'),(1, 'gCa_HVAbar_Ca_HVA'),(2, 'gCa_HVAbar_Ca_HVA'),(3, 'gCa_HVAbar_Ca_HVA'),(4, 'gCa_HVAbar_Ca_HVA'),(5, 'gCa_HVAbar_Ca_HVA'),(6, 'gCa_HVAbar_Ca_HVA'),  # gCA_HVA of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "            (0, 'gCa_LVAstbar_Ca_LVAst'),(1, 'gCa_LVAstbar_Ca_LVAst'),(2, 'gCa_LVAstbar_Ca_LVAst'),(3, 'gCa_LVAstbar_Ca_LVAst'),(4, 'gCa_LVAstbar_Ca_LVAst'),(5, 'gCa_LVAstbar_Ca_LVAst'),(6, 'gCa_LVAstbar_Ca_LVAst'),# gCA_LVAst of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "            (1, 'gImbar_Im'),(2, 'gImbar_Im'),(3, 'gImbar_Im'),(4, 'gImbar_Im'),(5, 'gImbar_Im'), # gIm of basal, midTrunk, distTrunk, tuft, axon\n",
        "            (0,'decay_CaDynamics_E2'),(1,'decay_CaDynamics_E2'),(2,'decay_CaDynamics_E2'),(3,'decay_CaDynamics_E2'),(4,'decay_CaDynamics_E2'),(5,'decay_CaDynamics_E2'),(6,'decay_CaDynamics_E2'), # decay_CaDynamics of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "            (0,'gamma_CaDynamics_E2'),(1,'gamma_CaDynamics_E2'),(2,'gamma_CaDynamics_E2'),(3,'gamma_CaDynamics_E2'),(4,'gamma_CaDynamics_E2'),(5,'gamma_CaDynamics_E2'),(6,'gamma_CaDynamics_E2'), # gamma_CaDynamics of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "            (0,'gIhbar_Ih'),(1,'gIhbar_Ih'),(2,'gIhbar_Ih'),(3,'gIhbar_Ih'),(4,'gIhbar_Ih'),(5,'gIhbar_Ih'),(6,'gIhbar_Ih'), # gIh of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "            (0,'gSK_E2bar_SK_E2'),(1,'gSK_E2bar_SK_E2'),(2,'gSK_E2bar_SK_E2'),(3,'gSK_E2bar_SK_E2'),(4,'gSK_E2bar_SK_E2'),(5,'gSK_E2bar_SK_E2'), # gSk_E2 of soma, basal, midTrunk, distTrunk, tuft, axon\n",
        "            (0,'gK_Tstbar_K_Tst'),(5,'gK_Tstbar_K_Tst'), # gK_Tst of soma, axon\n",
        "            (0,'gK_Pstbar_K_Pst'),(5,'gK_Pstbar_K_Pst'), # gK_Pst of soma, axon\n",
        "            (0,'gNap_Et2bar_Nap_Et2'),(5,'gNap_Et2bar_Nap_Et2') # gNap_Et2 of soma, axon\n",
        "        ]\n",
        "\n",
        "        default_biophys = np.array([0.0000338,0.0000467,0.0000489,0.0000589,0.0000589,0.0000325,0.0000100, # g_pas of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "                                    2.04,0.0213,0.0213,0.0213,0.0213,0.0,0.0, # gNaTa_t of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal # axon was 2.89618\n",
        "                                    0.693,0.000261,0.000261,0.000261,0.000261,0.0,0.0, # gSKv3_1 of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal #axon was 0.473799\n",
        "                                    0.000992,0.0,0.0000555,0.000555,.0000555,0.0,0.0,  # gCA_HVA of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal #basal was 0.000992\n",
        "                                    0.00343,0.0,0.000187,0.0187,0.000187,0.0,0.0, # gCA_LVAst of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "                                    0.0000675,0.0000675,0.0000675,0.0000675,0.0, # gIm of soma, basal, midTrunk, distTrunk, tuft, axon\n",
        "                                    460.0,122,122,122,122,277.300774,122, # decay_CaDynamics of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "                                    0.000501,0.000509,0.000509,0.000509,0.000509,0.000525,0.000509, # gamma_CaDynamics of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "                                    0.0002,0.0002,0.0002,0.00507257227,0.01535011884,0.0001,0.0002, # gIh of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "                                    0.0441,0.0012,0.0012,0.0012,0.0012,0.000047, # gSk_E2 of soma, basal, midTrunk, distTrunk, tuft, axon\n",
        "                                    0.0812,0.077274, # gK_Tst of soma, axon\n",
        "                                    0.00223,0.188851, # gK_Pst of soma, axon\n",
        "                                    0.00172,0.0  # gNap_Et2 of soma, axon\n",
        "                                    ])\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        if self.biophys is not None:\n",
        "            # print('length of default_biophys:',len(default_biophys))\n",
        "            # print('length of self.biophys:',len(self.biophys))\n",
        "            for i in range(len(self.biophys)):\n",
        "                if self.biophys[i]>=0:\n",
        "                    default_biophys[i]=self.biophys[i]\n",
        "        self.biophys = default_biophys\n",
        "    \n",
        "\n",
        "    def add_synapse(self,stim,sec_index,**kwargs):\n",
        "        \"\"\"Add synapse to a section by its index\"\"\"\n",
        "        self.injection.append(Synapse(self,stim,sec_index,**kwargs))\n",
        "        # self.syn_dist_list.append(self.syn_dist)\n",
        "        # self.gmax_list.append(self.gmax_list)\n",
        "        # self.P_0_list.append(self.)\n",
        "        # self.synapse_sec_list = []\n",
        " \n",
        "\n",
        "    def record_soma_v(self):\n",
        "        self.v_rec = Recorder(self.soma(.5),'v')\n",
        "    \n",
        "    def v(self):\n",
        "        \"\"\"Return recorded soma membrane voltage in numpy array\"\"\"\n",
        "        if hasattr(self,'v_rec'):\n",
        "\n",
        "            return self.v_rec.as_numpy()\n",
        "\n",
        "class Synapse(Point_current):\n",
        "    def __init__(self,cell,stim,sec_index,gmax=1,loc=0.5,record=True, SynType='exc',P_0=0.6): \n",
        "        super().__init__(cell,sec_index,loc)\n",
        "        self.stim = stim\n",
        "        self.gmax = gmax\n",
        "        self.loc = loc\n",
        "        self.syntype = SynType\n",
        "        self.P_0 = P_0\n",
        "        self.setup(record,loc,P_0,gmax)\n",
        "\n",
        "        \n",
        "\n",
        "    def setup(self,record,loc,P_0,gmax):\n",
        "        self.setup_synapse(loc,P_0,gmax)\n",
        "        if record:\n",
        "            self.setup_recorder()\n",
        "    \n",
        "    def setup_synapse(self,loc,P_0,gmax): \n",
        "        if self.syntype == 'inh':\n",
        "          self.pp_obj = h.int2pyr(self.get_section()(loc))\n",
        "          #Assigns random generator of release probability.\n",
        "          r = h.Random()\n",
        "          r.MCellRan4()\n",
        "          r.uniform(0,1)\n",
        "          self.pp_obj.setRandObjRef(r)\n",
        "          #A list of random generators is kept so that they are not automatically garbaged.\n",
        "          self.generator = r\n",
        "          syn = self.pp_obj\n",
        "          syn.setRandObjRef(r)\n",
        "          syn.P_0 = P_0\n",
        "          syn.initW = gmax\n",
        "          self.nc = h.NetCon(self.stim,syn,1,0,1)\n",
        "\n",
        "        else:\n",
        "          self.pp_obj = h.pyr2pyr(self.get_section()(loc))\n",
        "          #Assigns random generator of release probability.\n",
        "          r = h.Random()\n",
        "          r.MCellRan4()\n",
        "          r.uniform(0,1)\n",
        "          self.pp_obj.setRandObjRef(r)\n",
        "          #A list of random generators is kept so that they are not automatically garbaged.\n",
        "          self.generator = r\n",
        "          syn = self.pp_obj\n",
        "          syn.setRandObjRef(r)\n",
        "          syn.P_0 = P_0\n",
        "          syn.initW = gmax\n",
        "          self.nc = h.NetCon(self.stim,syn,1,0,1)\n",
        "\n",
        "    def setup_recorder(self):\n",
        "          size = [round(h.tstop/h.dt)+1] if hasattr(h,'tstop') else []\n",
        "          try:\n",
        "              self.rec_vec = h.Vector(*size).record(self.pp_obj._ref_igaba)\n",
        "          except:\n",
        "                  self.rec_vec = MultiSynCurrent()\n",
        "                  vec_inmda = h.Vector(*size).record(self.pp_obj._ref_inmda)\n",
        "                  vec_iampa = h.Vector(*size).record(self.pp_obj._ref_iampa)\n",
        "                  self.rec_vec.add_vec(vec_inmda)\n",
        "                  self.rec_vec.add_vec(vec_iampa)\n",
        "                  \n",
        "\n",
        "class MultiSynCurrent(object):\n",
        "    def __init__(self):\n",
        "        self.vec_list = []\n",
        "    \n",
        "    def add_vec(self,vec):\n",
        "        self.vec_list.append(vec)\n",
        "    \n",
        "    def as_numpy(self):\n",
        "        return np.sum(np.array([vec.as_numpy() for vec in self.vec_list]), axis=0)\n",
        "\n",
        "\n",
        "class Simulation(object):\n",
        "    def __init__(self,geometry,electrodes,loc_param=[0.,0.,0.,0.,1.,0.],\n",
        "                 geo_param=[-1],biophys=[-1],\n",
        "                 gmax=0.015,\n",
        "                 scale=1.0,ncell=1,\n",
        "                 spike_threshold: Optional[float] = None): #initially __init__(self,geometry,electrodes,loc_param=[0.,0.,0.,0.,1.,0.],geo_param=[-1],biophys=[-1],gmax=0.015,scale=1.0,ncell=1):\n",
        "        #exc_dens=2.16,\n",
        "       #\n",
        "        # inh_dens=0.22\n",
        "        \"\"\"\n",
        "        Initialize simulation object\n",
        "        geometry: pandas dataframe of cell morphology properties\n",
        "        electrodes: array of electrode coordinates, n-by-3\n",
        "        loc_param: location parameters, ncell-by-6 array, (x,y,z,theta,h,phi)\n",
        "        geo_param: geometry parameters, ncell-by-k array, if not specified, use default properties in geometry\n",
        "        biophys: biophysical parameters, ncell-by-k array, if not specified, use default properties\n",
        "        gmax: maximum conductance of synapse, ncell-vector, if is single value, is constant for all cells\n",
        "        scale: scaling factors of lfp magnitude, ncell-vector, if is single value, is constant for all cells\n",
        "        ncell: number of cells in the simulation, required if simulating for multiple cells\n",
        "        \"\"\"\n",
        "        self.ncell = ncell  # number of cells in this simulation\n",
        "        self.cells = []  # list of cell object\n",
        "        self.lfp = []  # list of EcpMod object\n",
        "        self.define_geometry_entries()  # list of entries to geometry dataframe\n",
        "        self.geometry = geometry.copy()\n",
        "        self.electrodes = electrodes\n",
        "        self.set_loc_param(loc_param)\n",
        "        self.set_geo_param(geo_param)\n",
        "        self.set_biophys(biophys)\n",
        "        self.set_gmax(gmax)\n",
        "        self.set_scale(scale)\n",
        "        self.create_cells()  #exc_dens,inh_dens, create cell objects with properties set up\n",
        "        self.t_vec = h.Vector( round(h.tstop/h.dt)+1 ).record(h._ref_t)  # record time\n",
        "        self.spike_threshold = None\n",
        "        self.record_spikes(spike_threshold)\n",
        "\n",
        "\n",
        "\n",
        "    def set_netstim(self, syn_number, inhfreq, excfreq, inhFRstd, excFRstd, syntype):\n",
        "        \"\"\"Setup spontaneous synaptic input event\"\"\"\n",
        "        stim_list = []\n",
        "        self.stim = stim_list\n",
        "        excFRlist=np.random.normal(loc=excfreq, scale=excFRstd, size=syn_number)\n",
        "        inhFRlist=np.random.normal(loc=inhfreq, scale=inhFRstd, size=syn_number)\n",
        "        for i in range(syn_number):\n",
        "          if syntype[i] == 'inh':\n",
        "            frequency = inhfreq\n",
        "            spikeinterval = 1000/frequency\n",
        "            stim = h.NetStim()\n",
        "            stim.number = 1000 #2  # average number of spikes #check that this does not affect spike freq. hopefully only affects duration of stim. \n",
        "            #max frequency input for L5 is 16 hz meaning stim.number should be at least tstop/30, but minimize number for better runtime\n",
        "            stim.start = 50 #(np.random.rand()*50)+50 #startspikes #50  #  most likely start time of first spike\n",
        "            stim.noise = 1  # fractional randomness\n",
        "            stim.interval =  spikeinterval #500  # mean time between spikes (ms)\n",
        "            #duration of stimulation = stim.interval X stim.number\n",
        "            stim_list.append(stim)\n",
        "          elif syntype[i] == 'exc':\n",
        "              frequency = excfreq\n",
        "              spikeinterval = 1000/frequency\n",
        "              stim = h.NetStim()\n",
        "              stim.number = 1000 #2  # average number of spikes #check that this does not affect spike freq. hopefully only affects duration of stim. \n",
        "              #max frequency input for L5 is 16 hz meaning stim.number should be at least tstop/30, but minimize number for better runtime\n",
        "              stim.start = 50 #(np.random.rand()*50)+50 #startspikes #50  #  most likely start time of first spike\n",
        "              stim.noise = 1  # fractional randomness\n",
        "              stim.interval =  spikeinterval #500  # mean time between spikes (ms)\n",
        "              #duration of stimulation = stim.interval X stim.number\n",
        "              stim_list.append(stim)\n",
        "    \n",
        "    def set_exc_grp_netstim(self, syn_number, excfreq, excFRstd, loc, grpx, clusterx, writer):\n",
        "        \"\"\"\n",
        "        Setup clustered synaptic exc input events\n",
        "        syn_number: the number of synapses\n",
        "        inhfreq/excfreq: mean inh/exc FR\n",
        "        inhFRstd/excFRstd: standard deviation of inh/exc FR\n",
        "        syntype: array of size syn_number containing 'inh' or 'exc'\n",
        "        loc: array of size syn_number containing 0<x<1 normalized location of synapse along section\n",
        "        grpx: array containing functional group bounds along section ex: [0,0.5,1]\n",
        "        clusterx: array containing cluster bounds along section ex: [0,0.2,0.4,0.6,0.8,1]\n",
        "        \"\"\"\n",
        "        stim_list = np.empty(syn_number, dtype=object)\n",
        "        self.stim = stim_list\n",
        "        ##may need to double check that these values are truly only exc if inh equivalent is unused\n",
        "        mean_fr=excfreq\n",
        "        std_fr=excFRstd\n",
        "        numclusters=len(clusterx)-1\n",
        "        numgrps=len(grpx)-1\n",
        "        #distribution used for generating excitatory firing rates.    \n",
        "        levy_dist = partial(st.levy_stable.rvs, alpha=1.37, beta=-1.00, loc=0.92, scale=0.44, size=1)\n",
        "        exc_dist=levy_dist(size=numclusters)\n",
        "        #normal distribution of cell firing rates\n",
        "        a, b = (0 - mean_fr) / std_fr, (100 - mean_fr) / std_fr #(0 - mean_fr) / std_fr, (100 - mean_fr) / std_fr\n",
        "        d = partial(st.truncnorm.rvs, a=a, b=b, loc=mean_fr, scale=std_fr) #Normal Distribution of cells\n",
        "        #buffer = self.params[\"time\"][\"start\"]\n",
        "        for k in range(numgrps): #iterate along functional groups\n",
        "          #generate the noise trace common to the functional group.\n",
        "          z = make_noise(num_samples=(int(tstop))-1,num_traces=1) # tstop was originally seconds*1000, num samples should be length of trace\n",
        "          ##may need to keep noise traces for inh synapses within functional group as well\n",
        "          rate_prof=np.tile(z[0,:],(numclusters,1))\n",
        "          for m in range(numclusters): #iterate through number of clusters\n",
        "            if (clusterx[m]>=grpx[k]) and (clusterx[m+1]<=grpx[k+1]): #may cause issue where cluster bounds surround a group edge instead of being within a group.\n",
        "              #get new single stim for cluster\n",
        "              rate_temp=[];simSpks_temp=[]\n",
        "              #pull excfr from modulated fr distribution\n",
        "              r=rate_prof[m,:]\n",
        "              r[r<0] = 0#Can't have negative firing rates.\n",
        "              rate_temp = r*np.exp(exc_dist[m])\n",
        "              #generate spikes given fr\n",
        "              numbPoints = st.poisson(rate_temp/1000).rvs()#Poisson number of points\n",
        "              simSpks=np.where(numbPoints>0)[0]\n",
        "              #create stim\n",
        "              excspikes=simSpks\n",
        "              if simSpks is None:\n",
        "                excspikes=[]\n",
        "              # NRN will fail if VecStim contains negative spike-time, throw an exception and log info for user\n",
        "              #print('spike train {} contains negative number, unable to run virtual cell in NEURON'.format(excspikes))\n",
        "              #get same stim for exc synapses in cluster\n",
        "              excspikes = np.sort(excspikes)\n",
        "              self._exc_train_vec = h.Vector(excspikes)\n",
        "              excvecstim = h.VecStim()\n",
        "              excvecstim.play(self._exc_train_vec)\n",
        "              self._hobj = excvecstim\n",
        "              for i in range(syn_number):\n",
        "                #make sure synapse is within current functional group\n",
        "                #if (loc[i]>=grpx[k]) and (loc[i]<=grpx[k+1]): #not necessary if you know current cluster is within current group already\n",
        "                  #assign stim to all synapses within current cluster\n",
        "                  if (loc[i]>=clusterx[m]) and (loc[i]<=clusterx[m+1]): #where location is between current group bound\n",
        "                      writer.append_repeat(\"node_ids\", i, len(simSpks))\n",
        "                      writer.append_ds(simSpks, \"timestamps\")\n",
        "                      stim_list[i]=excvecstim\n",
        "\n",
        "\n",
        "    def set_inh_grp_netstim(self, syn_number, inhfreq, inhFRstd, loc, grpx, clusterx, rhythmic_inh=True):\n",
        "        \"\"\"\n",
        "        Setup clustered synaptic input events\n",
        "        syn_number: the number of synapses\n",
        "        inhfreq/excfreq: mean inh/exc FR\n",
        "        inhFRstd/excFRstd: standard deviation of inh/exc FR\n",
        "        syntype: array of size syn_number containing 'inh' or 'exc'\n",
        "        loc: array of size syn_number containing 0<x<1 normalized location of synapse along section\n",
        "        grpx: array containing functional group bounds along section ex: [0,0.5,1]\n",
        "        clusterx: array containing cluster bounds along section ex: [0,0.2,0.4,0.6,0.8,1]\n",
        "        \"\"\"\n",
        "        stim_list = np.empty(syn_number, dtype=object)\n",
        "        self.stim = stim_list\n",
        "        ##may need to double check that these values are truly only exc if inh equivalent is unused\n",
        "        mean_fr=inhfreq\n",
        "        std_fr=inhFRstd\n",
        "        numclusters=len(clusterx)-1\n",
        "        numgrps=len(grpx)-1\n",
        "        #distribution used for generating excitatory firing rates.    \n",
        "        exc_dist = partial(st.levy_stable.rvs, alpha=1.37, beta=-1.00, loc=0.92, scale=0.44, size=1)\n",
        "        #normal distribution of cell firing rates\n",
        "        a, b = (0 - mean_fr) / std_fr, (100 - mean_fr) / std_fr #(0 - mean_fr) / std_fr, (100 - mean_fr) / std_fr\n",
        "        d = partial(st.truncnorm.rvs, a=a, b=b, loc=mean_fr, scale=std_fr) #Normal Distribution of cells\n",
        "        #buffer = self.params[\"time\"][\"start\"]\n",
        "        for k in range(numgrps): #iterate along functional groups\n",
        "          #generate the noise trace common to the functional group.\n",
        "          z = make_noise(num_samples=(int(tstop))-1,num_traces=1) # tstop was originally seconds*1000, num samples should be length of trace\n",
        "          if rhythmic_inh: # make an array of modulated sin waves\n",
        "            frs = d(size=syn_number)\n",
        "            t = np.arange(0,tstop,0.001)\n",
        "            z = np.zeros((syn_number,t.shape[0]))\n",
        "            P = 0\n",
        "            for i in np.arange(0,numclusters):\n",
        "              offset = frs[i]\n",
        "              rhythmic_mod=0.5\n",
        "              rhythmic_f=16\n",
        "              A = offset/((1/rhythmic_mod)-1)\n",
        "              z[i,:] = A*np.sin((2 * np.pi * rhythmic_f * t)+P) + offset\n",
        "              dist=np.ones((numclusters,1))\n",
        "          else: # create a noise trace by shifting exc spikes #\n",
        "              f = h5py.File(\"exc_stim_spikes.h5\", \"r\")\n",
        "              ts = f['spikes'][\"exc_stim\"]['timestamps'] #ts can be SimSpks from saving excitatory if the\n",
        "              nid = f['spikes'][\"exc_stim\"]['node_ids']\n",
        "              z = shift_exc_noise(ts, nid, tstop, time_shift=2) #z = shift_exc_noise(ts, nid, self.params[\"time\"][\"stop\"], time_shift=self.params[\"inh_shift\"])\n",
        "              z = np.tile(z,(numclusters,1))\n",
        "              dist=d(size=numclusters)\n",
        "          for m in range(numclusters):\n",
        "            if (clusterx[m]>=grpx[k]) and (clusterx[m+1]<=grpx[k+1]): #may cause issue where cluster bounds surround a group edge instead of being within a group.\n",
        "              #get new single stim for cluster\n",
        "              rate_temp=[];simSpks_temp=[]\n",
        "              rate_prof=np.tile(z[0,:],(numclusters,1))\n",
        "              r=rate_prof[m,:]\n",
        "              r[r<0] = 0#Can't have negative firing rates.\n",
        "              #pull inhfr from modulated fr distribution\n",
        "              rate_temp = r*dist[m]\n",
        "              #generate spikes given fr\n",
        "              numbPoints = st.poisson(rate_temp/1000).rvs()#Poisson number of points\n",
        "              simSpks=np.where(numbPoints>0)[0]\n",
        "              #create stim\n",
        "              inhspikes=simSpks\n",
        "              if simSpks is None:\n",
        "                inhspikes=[]\n",
        "              # NRN will fail if VecStim contains negative spike-time, throw an exception and log info for user\n",
        "              #print('spike train {} contains negative number, unable to run virtual cell in NEURON'.format(inhspikes))\n",
        "              #get same stim for inh synapse in cluster\n",
        "              #get same stim for inh synapses in cluster\n",
        "              inhspikes = np.sort(inhspikes)\n",
        "              self._inh_train_vec = h.Vector(inhspikes)\n",
        "              inhvecstim = h.VecStim()\n",
        "              inhvecstim.play(self._inh_train_vec)\n",
        "              # writer.append_repeat(\"node_ids\", i, len(simSpks))\n",
        "              # writer.append_ds(simSpks, \"timestamps\")\n",
        "              self._hobj = inhvecstim\n",
        "              #for k in range(numgrps): #iterate along functional groups\n",
        "                #for m in range(numclusters):\n",
        "                #if (clusterx[m]>=grpx[k]) and (clusterx[m+1]<=grpx[k+1]):\n",
        "              for i in range(syn_number):\n",
        "                #make sure synapse is within current functional group\n",
        "                #if (loc[i]>=grpx[k]) and (loc[i]<=grpx[k+1]): #not necessary if you know current cluster is within current group already\n",
        "                  #assign stim to all synapses within current cluster\n",
        "                  if (loc[i]>=clusterx[m]) and (loc[i]<=clusterx[m+1]): #where location is between current group bound\n",
        "                      stim_list[i]=inhvecstim\n",
        "\n",
        "\n",
        "    \n",
        "    def pack_parameters(self,param,ndim,param_name):\n",
        "        \"\"\"Pack parameters for the simulation\"\"\"\n",
        "        if ndim==0:\n",
        "            if not hasattr(param,'__len__'):\n",
        "                param = [param]\n",
        "            param = np.array(param).ravel()\n",
        "            if param.size!=self.ncell:\n",
        "                if param.size==1:\n",
        "                    param = np.broadcast_to(param,self.ncell)\n",
        "                else:\n",
        "                    raise ValueError(param_name+\" size does not match ncell\")   \n",
        "        if ndim==1:\n",
        "            param = np.array(param)\n",
        "            if param.ndim==1:\n",
        "                param = np.expand_dims(param,0)\n",
        "            if param.shape[0]!=self.ncell:\n",
        "                if param.shape[0]==1:\n",
        "                    param = np.broadcast_to(param,(self.ncell,param.shape[1]))\n",
        "                else:\n",
        "                    raise ValueError(param_name+\" number of rows does not match ncell\")\n",
        "        return param\n",
        "    \n",
        "    def set_loc_param(self,loc_param):\n",
        "        \"\"\"Setup location parameters. loc_param ncell-by-6 array\"\"\"\n",
        "        loc_param = self.pack_parameters(loc_param,1,\"loc_param\")\n",
        "        self.loc_param = [(loc_param[i,:3],loc_param[i,3:]) for i in range(self.ncell)]\n",
        "    \n",
        "    def set_geo_param(self,geo_param):\n",
        "        \"\"\"Setup geometry parameters. geo_param ncell-by-k array, k entries of properties\"\"\"\n",
        "        self.geo_param = self.pack_parameters(geo_param,1,\"geo_param\")\n",
        "    \n",
        "    def set_biophys(self,biophys):\n",
        "        \"\"\"Setup geometry parameters. geo_param ncell-by-k array, k entries of properties\"\"\"\n",
        "        self.biophys = self.pack_parameters(biophys,1,\"biophys\")\n",
        "    \n",
        "    # def set_gmax(self,gmaxEXC,gmaxINH):\n",
        "    #     \"\"\"Setup maximum conductance of synapse\"\"\"\n",
        "    #     self.gmaxEXC = self.pack_parameters(gmaxEXC,0,\"gmaxEXC\")\n",
        "    #     self.gmaxINH = self.pack_parameters(gmaxINH,0,\"gmaxINH\")\n",
        "    def set_gmax(self,gmax):\n",
        "        \"\"\"Setup maximum conductance of synapse\"\"\"\n",
        "        self.gmax = self.pack_parameters(gmax,0,\"gmax\")\n",
        "    \n",
        "    def set_scale(self,scale):\n",
        "        \"\"\"setup scaling factors of lfp magnitude\"\"\"\n",
        "        self.scale = self.pack_parameters(scale,0,\"scale\")\n",
        "    \n",
        "    def define_geometry_entries(self):\n",
        "        \"\"\"Define list of entries to geometry dataframe. Each entry is a pair of section id and property.\"\"\"\n",
        "        self.geo_entries = [\n",
        "            #soma\n",
        "            (0,'R'),  # radius\n",
        "            #proximal trunk\n",
        "            (4,'excitation'), # excitation ('TRUE'/'FALSE')\n",
        "            (4,'inhibition'), # inhibition ('TRUE'/'FALSE')\n",
        "            (4,'L'), # length\n",
        "            (4,'R'), # radius\n",
        "            (4,'excFRmean'), # exc FR mean\n",
        "            (4,'excFRstd'), # exc FR std\n",
        "            (4,'inhFRmean'), # inh FR mean\n",
        "            (4,'inhFRstd'), # inh FR std\n",
        "            (4,'excP_0mean'), # exc P_0 mean (0 to 1)\n",
        "            (4,'excP_0std'), # exc P_0 std\n",
        "            (4,'inhP_0mean'), # inh P_0 mean (0 to 1)\n",
        "            (4,'inhP_0std'), # inh P_0 std\n",
        "            #middle trunk\n",
        "            (6,'excitation'), # excitation ('TRUE'/'FALSE')\n",
        "            (6,'inhibition'), # inhibition ('TRUE'/'FALSE')\n",
        "            (6,'L'), # length\n",
        "            (6,'R'), # radius\n",
        "            (6,'excFRmean'), # exc FR mean\n",
        "            (6,'excFRstd'), # exc FR std\n",
        "            (6,'inhFRmean'), # inh FR mean\n",
        "            (6,'inhFRstd'), # inh FR std\n",
        "            (6,'excP_0mean'), # exc P_0 mean (0 to 1)\n",
        "            (6,'excP_0std'), # exc P_0 std\n",
        "            (6,'inhP_0mean'), # inh P_0 mean (0 to 1)\n",
        "            (6,'inhP_0std'), # inh P_0 std\n",
        "            #distal trunk\n",
        "            (7,'excitation'), # excitation ('TRUE'/'FALSE')\n",
        "            (7,'inhibition'), # inhibition ('TRUE'/'FALSE')\n",
        "            (7,'L'), # length\n",
        "            (7,'R'), # radius\n",
        "            (7,'excFRmean'), # exc FR mean\n",
        "            (7,'excFRstd'), # exc FR std\n",
        "            (7,'inhFRmean'), # inh FR mean\n",
        "            (7,'inhFRstd'), # inh FR std\n",
        "            (7,'excP_0mean'), # exc P_0 mean (0 to 1)\n",
        "            (7,'excP_0std'), # exc P_0 std\n",
        "            (7,'inhP_0mean'), # inh P_0 mean (0 to 1)\n",
        "            (7,'inhP_0std'), # inh P_0 std\n",
        "            #basal dendrites\n",
        "            ([1,2,3],'excitation'), # excitation ('TRUE'/'FALSE')\n",
        "            ([1,2,3],'inhibition'), # inhibition ('TRUE'/'FALSE')\n",
        "            ([1,2,3],'nbranch'), # number of dendrites\n",
        "            (1,'L'), # proximal section length\n",
        "            (2,'L'), # middle section length\n",
        "            (3,'L'), # distal section length\n",
        "            (1,'R'), # proximal radius\n",
        "            (2,'R'), # middle radius\n",
        "            (3,'R'), # distal radius\n",
        "            ([1,2,3],'ang'), # angle\n",
        "            ([1,2,3],'excFRmean'), # exc FR mean\n",
        "            ([1,2,3],'excFRstd'), # exc FR std\n",
        "            ([1,2,3],'inhFRmean'), # inh FR mean\n",
        "            ([1,2,3],'inhFRstd'), # inh FR std\n",
        "            ([1,2,3],'excP_0mean'), # exc P_0 mean (0 to 1)\n",
        "            ([1,2,3],'excP_0std'), # exc P_0 std\n",
        "            ([1,2,3],'inhP_0mean'), # inh P_0 mean (0 to 1)\n",
        "            ([1,2,3],'inhP_0std'), # inh P_0 std\n",
        "            #oblique dendrites\n",
        "            (5,'excitation'), # excitation ('TRUE'/'FALSE')\n",
        "            (5,'inhibition'), # inhibition ('TRUE'/'FALSE')\n",
        "            (5,'nbranch'), # number of dendrites\n",
        "            (5,'L'), # length\n",
        "            (5,'R'), # radius\n",
        "            (5,'ang'), # angle\n",
        "            (5,'excFRmean'), # exc FR mean\n",
        "            (5,'excFRstd'), # exc FR std\n",
        "            (5,'inhFRmean'), # inh FR mean\n",
        "            (5,'inhFRstd'), # inh FR std\n",
        "            (5,'excP_0mean'), # exc P_0 mean (0 to 1)\n",
        "            (5,'excP_0std'), # exc P_0 std\n",
        "            (5,'inhP_0mean'), # inh P_0 mean (0 to 1)\n",
        "            (5,'inhP_0std'), # inh P_0 std\n",
        "            # tuft dendrites\n",
        "            ([8,9,10],'excitation'), # excitation ('TRUE'/'FALSE')\n",
        "            ([8,9,10],'inhibition'), # inhibition ('TRUE'/'FALSE')\n",
        "            ([8,9,10],'nbranch'), # number of dendrites\n",
        "            (8,'L'), # proximal section length\n",
        "            (9,'L'), # middle section length\n",
        "            (10,'L'), # distal section length\n",
        "            (8,'R'), # proximal radius\n",
        "            (9,'R'), # middle radius\n",
        "            (10,'R'), # distal radius\n",
        "            ([8,9,10],'ang'), # angle\n",
        "            ([8,9,10],'excFRmean'), # exc FR mean\n",
        "            ([8,9,10],'excFRstd'), # exc FR std\n",
        "            ([8,9,10],'inhFRmean'), # inh FR mean\n",
        "            ([8,9,10],'inhFRstd'), # inh FR std\n",
        "            ([8,9,10],'excP_0mean'), # exc P_0 mean (0 to 1)\n",
        "            ([8,9,10],'excP_0std'), # exc P_0 std\n",
        "            ([8,9,10],'inhP_0mean'), # inh P_0 mean (0 to 1)\n",
        "            ([8,9,10],'inhP_0std'), # inh P_0 std\n",
        "            #axon\n",
        "            (11,'L'), # length\n",
        "            (11,'R'), # radius\n",
        "            #passive basal\n",
        "            (12,'nbranch'), # number of dendrites\n",
        "            (12,'L'), # length\n",
        "            (12,'R') # radius\n",
        "        ]\n",
        "    \n",
        "    def set_geometry(self,geometry,geo_param):\n",
        "        \"\"\"Set property values from geo_param through each entry to geometry. Return dataframe\"\"\"\n",
        "        geom = geometry.copy()\n",
        "        for i,x in enumerate(geo_param):\n",
        "            if x>=0:\n",
        "                geom.loc[self.geo_entries[i]] = x\n",
        "        return geom\n",
        "\n",
        "    def record_spikes(self, threshold: Optional[float]) -> None:\n",
        "        \"\"\"Setup spike recorder for all cells\"\"\"\n",
        "        for cell in self.cells:\n",
        "            cell.set_spike_recorder(threshold)\n",
        "        self.spike_threshold = threshold\n",
        "\n",
        "    def create_cells(self): #exc_dens,inh_dens\n",
        "\n",
        "        \"\"\"Create cell objects with properties set up\"\"\"\n",
        "        self.cells.clear()  # remove cell objects from previous run\n",
        "        self.lfp.clear()\n",
        "        # Create cell with morphology and biophysical parameters\n",
        "        for i in range(self.ncell):\n",
        "            geometry = self.set_geometry(self.geometry,self.geo_param[i,:])\n",
        "            self.cells.append( Cell(geometry=geometry,biophys=self.biophys[i,:]) )\n",
        "        # add injection current or synaptic current and set up lfp recording\n",
        "        min_dist = 10.0 # minimum distance allowed between segment and electrode. Set to None if not using.\n",
        "        for i,cell in enumerate(self.cells):\n",
        "          self.lfp.append( EcpMod(cell,self.electrodes,move_cell=self.loc_param[i],scale=self.scale[i],min_distance=min_dist) )\n",
        "          #Current injection in soma\n",
        "          cell.add_injection(sec_index=0,record=True,delay=150,dur=850,amp=-0.1) # Tune for proper action potential \n",
        "\n",
        "          # # cell.add_injection(sec_index=19,record=True,delay=150,dur=150,amp=0.1) # Tune for proper action potential\n",
        "          # writer = SonataWriter('exc_stim_spikes.h5', [\"spikes\", \"exc_stim\"], [\"timestamps\", \"node_ids\"], [np.float, np.int])\n",
        "          # for id,sec in self.geometry.iterrows(): #add exc synapses\n",
        "          #     sec_index_list=cell.sec_id_lookup[id]\n",
        "          #     L = sec['L']\n",
        "          #     #Clustering\n",
        "          #     funcgrouplength=100 #desired functional group length (um)      #warning: rounding may alter\n",
        "          #     clusterlength=5 #desired cluster length (um)                    #warning: rounding may alter\n",
        "          #     #calculate number of functional groups and clusters on this section\n",
        "          #     funcgrps=round(L/funcgrouplength)\n",
        "          #     clusters=int(np.floor(L/clusterlength))\n",
        "          #     if funcgrps==0:\n",
        "          #       funcgrps=1\n",
        "          #     if clusters==0:\n",
        "          #       clusters=1\n",
        "          #     #print('The number of clusters is ',clusters)\n",
        "          #     #calculate the bounds of functional groups on this section\n",
        "          #     grpx=[]\n",
        "          #     for num in range(funcgrps):\n",
        "          #       grpx.append(num/funcgrps)\n",
        "          #     grpx.append(1)\n",
        "          #     #print('grpx for ',sec['name'],funcgrps,' is ',grpx)\n",
        "          #     #calculate the bounds of clusters on this section\n",
        "          #     clusterx=[]\n",
        "          #     for num in range(clusters):\n",
        "          #       clusterx.append(num/clusters)\n",
        "          #     clusterx.append(1)\n",
        "          #     #print('clusterx for ',sec['name'],clusters,' is ',clusterx)\n",
        "          #     #print(funcgrps)\n",
        "\n",
        "          #     #pull section synaptic parameters\n",
        "          #     excP_0mean=sec['excP_0mean']\n",
        "          #     excP_0std=sec['excP_0std']\n",
        "          #     excFRmean=sec['excFRmean']\n",
        "          #     excFRstd=sec['excFRstd']\n",
        "          #     excitation=sec['excitation']\n",
        "          #     exc_dens=sec['exc_dens']\n",
        "\n",
        "          #     if sec['excitation']:\n",
        "          #         print('Distributing exc synapses onto',sec['name'],'sections')\n",
        "          #         syn_exc_number = np.round((exc_dens)*L) # number of synapses on dendrites = density (syn/um) times length of dendrites (um)\n",
        "          #         syn_number = int(syn_exc_number) #total number of synapses on the section\n",
        "          #         for isec in range(len(sec_index_list)):\n",
        "          #             #print(sec['name'],'has ',funcgrps,' groups and ',syn_number,' synapses')\n",
        "          #             syn_dist = np.random.rand(syn_number) #generate random values for 'x' normalized location along section\n",
        "          #             if id == 10:\n",
        "          #               gmax_dist = np.random.lognormal(mean, std, syn_number) #generate random values for gmax # change gmax for distal tuft\n",
        "          #             else:\n",
        "          #               gmax_dist = np.random.lognormal(mean, std, syn_number) #generate random values for gmax\n",
        "          #             self.set_exc_grp_netstim(syn_number,excfreq=excFRmean,excFRstd=excFRstd, loc=syn_dist, grpx=grpx, clusterx=clusterx, writer=writer) #generate exc presynaptic spike trains\n",
        "          #             P_0exclist=np.random.normal(loc=excP_0mean, scale=excP_0std, size=syn_number)\n",
        "          #             for j in range(syn_number):\n",
        "          #               cell.add_synapse(stim=self.stim[j],sec_index=sec_index_list[isec],gmax=gmax_dist[j],loc=syn_dist[j],SynType='exc',P_0=P_0exclist[j])\n",
        "          #     else: \n",
        "          #         print(sec['name'],'has no exc synapses')\n",
        "\n",
        "          # for id,sec in self.geometry.iterrows(): #add inh synapses\n",
        "          #     sec_index_list=cell.sec_id_lookup[id]\n",
        "          #     L = sec['L']\n",
        "          #     #Clustering\n",
        "          #     funcgrouplength=100 #desired functional group length (um)      #warning: rounding may alter\n",
        "          #     clusterlength=5 #desired cluster length (um)                    #warning: rounding may alter\n",
        "          #     #calculate number of functional groups and clusters on this section\n",
        "          #     funcgrps=round(L/funcgrouplength)\n",
        "          #     clusters=int(np.floor(L/clusterlength))\n",
        "          #     if funcgrps==0:\n",
        "          #       funcgrps=1\n",
        "          #     if clusters==0:\n",
        "          #       clusters=1\n",
        "          #     #print('The number of clusters is ',clusters)\n",
        "          #     #calculate the bounds of functional groups on this section\n",
        "          #     grpx=[]\n",
        "          #     for num in range(funcgrps):\n",
        "          #       grpx.append(num/funcgrps)\n",
        "          #     grpx.append(1)\n",
        "          #     #print('grpx for ',sec['name'],funcgrps,' is ',grpx)\n",
        "          #     #calculate the bounds of clusters on this section\n",
        "          #     clusterx=[]\n",
        "          #     for num in range(clusters):\n",
        "          #       clusterx.append(num/clusters)\n",
        "          #     clusterx.append(1)\n",
        "          #     #print('clusterx for ',sec['name'],clusters,' is ',clusterx)\n",
        "          #     #print(funcgrps)\n",
        "\n",
        "          #     #pull section synaptic parameters for section\n",
        "          #     inhP_0mean=sec['inhP_0mean']\n",
        "          #     inhP_0std=sec['inhP_0std']\n",
        "          #     inhFRmean=sec['inhFRmean']\n",
        "          #     inhFRstd=sec['inhFRstd']\n",
        "          #     inhibition=sec['inhibition']\n",
        "          #     inh_dens=sec['inh_dens']\n",
        "          #     rhythmic_inh=sec['rhythmic_inh']\n",
        "          #     if sec['inhibition']:\n",
        "          #       print('Distributing inh synapses onto',sec['name'],'sections')\n",
        "          #       if id==0: # soma\n",
        "          #       ### add specific inhibition to soma\n",
        "          #         syn_number = 406\n",
        "          #       else:\n",
        "          #         syn_inh_number = np.round((inh_dens)*L) # number of synapses on dendrites = density (syn/um) times length of dendrites (um)\n",
        "          #         syn_number = int(syn_inh_number) #total number of synapses on the section\n",
        "          #       for isec in range(len(sec_index_list)):\n",
        "          #           #print(sec['name'],'has ',funcgrps,' groups and ',syn_number,' synapses')\n",
        "          #           syn_dist = np.random.rand(syn_number) #generate random values for 'x' normalized location along section\n",
        "          #           if id == 10:\n",
        "          #             gmax_dist = np.random.lognormal(mean, std, syn_number) #generate random values for gmax # change gmax for distal tuft\n",
        "          #           else:\n",
        "          #             gmax_dist = np.random.lognormal(mean, std, syn_number) #generate random values for gmax\n",
        "          #           self.set_inh_grp_netstim(syn_number,inhfreq=inhFRmean,inhFRstd=inhFRstd, loc=syn_dist, rhythmic_inh=rhythmic_inh, clusterx=clusterx, grpx=grpx) #generate inh presynaptic spike trains\n",
        "          #           P_0inhlist=np.random.normal(loc=inhP_0mean, scale=inhP_0std, size=syn_number)\n",
        "          #           for j in range(syn_number):\n",
        "          #             cell.add_synapse(stim=self.stim[j],sec_index=sec_index_list[isec],gmax=1,loc=syn_dist[j],SynType='inh',P_0=P_0inhlist[j])\n",
        "          #     else: \n",
        "          #         print(sec['name'],'has no inh synapses')\n",
        "\n",
        "        # Old implementation\n",
        "        # for i,cell in enumerate(self.cells):\n",
        "        #   self.lfp.append( EcpMod(cell,self.electrodes,move_cell=self.loc_param[i],scale=self.scale[i],min_distance=min_dist) )\n",
        "        #   # Current injection in soma\n",
        "        #   #cell.add_injection(sec_index=19,record=True,delay=150,dur=150,amp=0.1) # Tune for proper action potential \n",
        "        #   for id,sec in self.geometry.iterrows(): #add exc synapses\n",
        "        #       sec_index_list=cell.sec_id_lookup[id]\n",
        "        #       L = sec['L']\n",
        "        #       #pull section synaptic parameters\n",
        "        #       excP_0mean=sec['excP_0mean']\n",
        "        #       excP_0std=sec['excP_0std']\n",
        "        #       inhP_0mean=sec['inhP_0mean']\n",
        "        #       inhP_0std=sec['inhP_0std']\n",
        "        #       excFRmean=sec['excFRmean']\n",
        "        #       excFRstd=sec['excFRstd']\n",
        "        #       inhFRmean=sec['inhFRmean']\n",
        "        #       inhFRstd=sec['inhFRstd']\n",
        "        #       inhibition=sec['inhibition']\n",
        "        #       excitation=sec['excitation']\n",
        "        #       inh_dens=sec['inh_dens']\n",
        "        #       exc_dens=sec['exc_dens']\n",
        "        #       rhythmic_inh=sec['rhythmic_inh']\n",
        "\n",
        "        #       if id==0: # soma\n",
        "        #         #print('soma skipped') #skip soma\n",
        "        #         ### add specific inhibition to soma\n",
        "        #         syn_number = 406\n",
        "        #         #print(self.stim)\n",
        "        #         syn_dist = np.random.rand(syn_number) #generate distribution for location\n",
        "        #         syn_type_list = ['inh' for y in range(syn_number)] #assign randomly, adhere to proportion\n",
        "        #         #print(syn_type_list)\n",
        "        #         self.set_netstim(syn_number,inhfreq=inhFRmean,excfreq=excFRmean,excFRstd=excFRstd,inhFRstd=inhFRstd,syntype=syn_type_list)\n",
        "        #         # print(self.stim)\n",
        "        #         P_0inhlist=np.random.normal(loc=inhP_0mean, scale=inhP_0std, size=syn_number)\n",
        "        #         P_0exclist=np.random.normal(loc=excP_0mean, scale=excP_0std, size=syn_number)\n",
        "        #         for j in range(syn_number):\n",
        "        #           cell.add_synapse(stim=self.stim[j],sec_index=sec_index_list[0],gmax=1,loc=syn_dist[j],SynType=syn_type_list[j],P_0=P_0inhlist[j])\n",
        "\n",
        "        #       else: # add synapses to each section\n",
        "        #           if sec['excitation']:\n",
        "        #               syn_exc_number = np.round((exc_dens)*L) # number of synapses on dendrites = density (syn/um) times length of dendrites (um)\n",
        "        #           else: \n",
        "        #               syn_exc_number=0\n",
        "        #           if sec['inhibition']:\n",
        "        #               syn_inh_number = np.round((inh_dens)*L)\n",
        "        #           else:\n",
        "        #               syn_inh_number=0\n",
        "        #           if (not sec['inhibition']) and (not sec['excitation']):\n",
        "        #               print(sec['name'],'has no synapses')\n",
        "        #           else:\n",
        "        #               syn_number = int(syn_inh_number + syn_exc_number) #total number of synapses on the section\n",
        "        #               prop_exc = syn_exc_number/syn_number #used for assigning type\n",
        "        #               for isec in range(len(sec_index_list)):\n",
        "        #                   #print(sec['name'],'has ',funcgrps,' groups and ',syn_number,' synapses')\n",
        "        #                   syn_dist = np.random.rand(syn_number) #generate random values for 'x' normalized location along section\n",
        "        #                   rand_syntype = np.random.rand(syn_number)  #generate random values for determining type\n",
        "        #                   gmax_dist = np.random.lognormal(mean, std, syn_number) #generate random values for gmax\n",
        "        #                   syn_type_list = ['exc' if y< prop_exc else #generate list of synapse type by assigning type using random values \n",
        "        #                                   'inh' for y in rand_syntype]\n",
        "        #                   self.set_netstim(syn_number,inhfreq=inhFRmean,excfreq=excFRmean,excFRstd=excFRstd,inhFRstd=inhFRstd,syntype=syn_type_list) #generate list of presynaptic spike trains\n",
        "        #                   P_0exclist=np.random.normal(loc=excP_0mean, scale=excP_0std, size=syn_number)\n",
        "        #                   P_0inhlist=np.random.normal(loc=inhP_0mean, scale=inhP_0std, size=syn_number)\n",
        "        #                   for j in range(syn_number): #add synapses using list indices\n",
        "        #                     if syn_type_list[j] == 'exc':\n",
        "        #                       cell.add_synapse(stim=self.stim[j],sec_index=sec_index_list[isec],gmax=gmax_dist[j],loc=syn_dist[j],SynType=syn_type_list[j],P_0=P_0exclist[j])\n",
        "        #                     elif syn_type_list[j] == 'inh':\n",
        "        #                       cell.add_synapse(stim=self.stim[j],sec_index=sec_index_list[isec],gmax=1,loc=syn_dist[j],SynType=syn_type_list[j],P_0=P_0inhlist[j])\n",
        "        #                     else:\n",
        "        #                       print('Error: syn_type not exc/inh')\n",
        "          \n",
        "\n",
        "        \n",
        "\n",
        "    \n",
        "    def run(self):\n",
        "        \"\"\"Run simulation\"\"\"\n",
        "        h.run()\n",
        "    \n",
        "    def t(self):\n",
        "        \"\"\"Return simulation time vector\"\"\"\n",
        "        return self.t_vec.as_numpy()\n",
        "    \n",
        "    def get_lfp(self,index=0):\n",
        "        \"\"\"Return LFP array of the cell by index (indices), (cells-by-)channels-by-time\"\"\"\n",
        "        if not hasattr(index,'__len__'):\n",
        "            lfp = self.lfp[index].calc_ecp()\n",
        "        else:\n",
        "            index = np.asarray(index).ravel()\n",
        "            lfp = np.stack([self.lfp[i].calc_ecp() for i in index],axis=0)\n",
        "        return lfp\n",
        "\n",
        "    def get_spike_time(self, index: Union[np.ndarray, List[int], int, str] = 0) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Return soma spike time of the cell by index (indices), ndarray (list of ndarray)\n",
        "        Parameters\n",
        "        index: index of the cell to retrieve the spikes from\n",
        "        \"\"\"\n",
        "        if self.spike_threshold is None:\n",
        "            raise ValueError(\"Spike recorder was not set up.\")\n",
        "        if type(index) is str and index == 'all':\n",
        "            index = range(self.ncell)\n",
        "        if not hasattr(index, '__len__'):\n",
        "            spk = self.cells[index].spikes.as_numpy().copy()\n",
        "        else:\n",
        "            index = np.asarray(index).ravel()\n",
        "            spk = np.array([self.cells[i].spikes.as_numpy().copy() for i in index], dtype=object)\n",
        "        return spk\n",
        "\n",
        "    def get_spike_number(self, index: Union[np.ndarray, List[int], int, str] = 0) -> Union[int, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Return soma spike number of the cell by index (indices), int (ndarray)\n",
        "        Parameters\n",
        "        index: index of the cell to retrieve the spikes from\n",
        "        \"\"\"\n",
        "        if self.spike_threshold is None:\n",
        "            raise ValueError(\"Spike recorder was not set up.\")\n",
        "        if index == 'all':\n",
        "            index = range(self.ncell)\n",
        "        if not hasattr(index, '__len__'):\n",
        "            spk = self.get_spike_time(index)\n",
        "            nspk = spk.size\n",
        "        else:\n",
        "            index = np.asarray(index).ravel()\n",
        "            spk = self.get_spike_time(index)\n",
        "            nspk = np.array([s.size for s in spk])\n",
        "        return nspk, "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Hd_BY_pSVuGS"
      },
      "outputs": [],
      "source": [
        "class Nexus_Axial_Current(object):\n",
        "    \"\"\"A module for recording axial currents from nexus to segments attached to nexus\"\"\"\n",
        "    def __init__(self, disttrunk: nrn.Section, dend_type: Optional[str] = None, record_t: bool = False, single_seg: bool = False) -> None:\n",
        "        \"\"\"\n",
        "        disttrunk: disttrunk section object\n",
        "        dend_type: list of section names of the dendrite types that need to be recorded\n",
        "        record_t: whether or not to record time points\n",
        "        single_seg: whether or not to record only one segment for each dendrite type\n",
        "        \"\"\"\n",
        "        self.disttrunk = disttrunk\n",
        "        if dend_type is None:\n",
        "            sec_names = [sec.name().split('.')[-1].split('[')[0] for sec in disttrunk.children()]\n",
        "            self.dend_type = list(set(sec_names))\n",
        "        else:\n",
        "            self.dend_type = dend_type\n",
        "        self.dend = {};\n",
        "        for d in self.dend_type:\n",
        "            self.dend[d] = Adjacent_Section(self.disttrunk,d)\n",
        "        self.single_seg = single_seg\n",
        "        self.setup_recorder(record_t)\n",
        "    \n",
        "    def setup_recorder(self, record_t: bool = False):\n",
        "        if record_t:\n",
        "            self.t_vec = h.Vector(round(h.tstop / h.dt) + 1).record(h._ref_t)\n",
        "        else:\n",
        "            self.t_vec = None\n",
        "        for dend in self.dend.values():\n",
        "            dend.setup_recorder(self.single_seg)\n",
        "    \n",
        "    def t(self):\n",
        "        if self.t_vec is None:\n",
        "            t = None\n",
        "        else:\n",
        "            t = self.t_vec.as_numpy().copy()\n",
        "        return t\n",
        "    \n",
        "    def get_current(self, dend_type: Optional[str] = None) -> np.ndarray:\n",
        "        if dend_type is None:\n",
        "            axial_current = {}\n",
        "            for name,dend in self.dend.items():\n",
        "                axial_current[name] = dend.get_current()\n",
        "        else:\n",
        "            axial_current = self.dend[dend_type].get_current()\n",
        "        return axial_current\n",
        "\n",
        "class Adjacent_Section(object):\n",
        "    \"\"\"A module for recording and calculating axial current from the soma to its adjacent sections of a dendrite type\"\"\"\n",
        "    def __init__(self, disttrunk: nrn.Section, name: Optional[str] = 'dend') -> None:\n",
        "        \"\"\"\n",
        "        disttrunk: disttrunk section object\n",
        "        name: section names of the dendrite type\n",
        "        \"\"\"\n",
        "        self.name = name\n",
        "        self.init_sec = [s for s in disttrunk.children() if name in s.name()]\n",
        "        self.nseg = [s.nseg for s in self.init_sec]\n",
        "        self.init_seg = [s(0.5/n) for s,n in zip(self.init_sec,self.nseg)]\n",
        "    \n",
        "    def setup_recorder(self, single_seg: bool = False):\n",
        "        self.soma_seg = [s.parentseg() for s in self.init_sec]\n",
        "        if len(set(self.soma_seg)) == 1 and len(self.soma_seg)>1:\n",
        "            self.soma_seg = [self.soma_seg[0]]\n",
        "        if single_seg:\n",
        "            self.init_seg = [self.init_seg[0]]\n",
        "        self.soma_v = Recorder(self.soma_seg)\n",
        "        self.dend_v = Recorder(self.init_seg)\n",
        "    \n",
        "    def get_current(self) -> np.ndarray:\n",
        "        v_soma = self.soma_v.as_numpy()\n",
        "        v_dend = self.dend_v.as_numpy()\n",
        "        axial_r = np.array([[seg.ri()] for seg in self.init_seg])\n",
        "        axial_current = (v_soma-v_dend)/axial_r\n",
        "        return axial_current"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER4RehApD8dM"
      },
      "source": [
        "## Create simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "q6-0DfThD8dN"
      },
      "outputs": [],
      "source": [
        "x = np.zeros(96)\n",
        "y = np.linspace(-1900,1900,96)\n",
        "z = np.zeros(96)\n",
        "elec_pos = pos = np.column_stack((x,y,z))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59qptuG3D8dO"
      },
      "source": [
        "Set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "w-bIgCdCD8dP",
        "scrolled": true,
        "outputId": "68d2befa-f316-423f-f3f2-301ec441cde7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It took 0 sec to define the simulation model.\n"
          ]
        }
      ],
      "source": [
        "loc_param = [50,0,10,0,1,0]  # example position #D: initially this was [0,0,50,0.2,0.75,1.5], (x,y,z,theta,h,phi), h=[-1,1] phi=[-pi,pi] h=.7071067812 for 90 deg\n",
        "#note on parameters: Rotate(alpha,h,phi): first rotate alpha about y-axis (spin), then rotate arccos(h) about x-axis (elevation), then rotate phi about y axis (azimuth).\n",
        "\n",
        "\n",
        "# change geo_parameters from their default values #************************NOTE**********************: doesn't change the geometry values used in geom_iterrows & sec['parameter'] (like when synapses are adding using geom);\n",
        "geo_param = [ # -1 uses default value                                                                  #better to edit the geom file to guarantee edits until the automation is fixed\n",
        "            #soma\n",
        "            -1,  # radius\n",
        "#proximal trunk\n",
        "            -1, # excitation ('TRUE'/'FALSE')\n",
        "            -1, # inhibition ('TRUE'/'FALSE')\n",
        "            -1, # length\n",
        "            -1, # radius\n",
        "            -1, # exc FR mean\n",
        "            -1, # exc FR std\n",
        "            -1, # inh FR mean\n",
        "            -1, # inh FR std\n",
        "            -1, # exc P_0 mean (0 to 1)\n",
        "            -1, # exc P_0 std\n",
        "            -1, # inh P_0 mean (0 to 1)\n",
        "            -1, # inh P_0 std\n",
        "#middle trunk\n",
        "            -1, # excitation ('TRUE'/'FALSE')\n",
        "            -1, # inhibition ('TRUE'/'FALSE')\n",
        "            -1, # length\n",
        "            -1, # radius\n",
        "            -1, # exc FR mean\n",
        "            -1, # exc FR std\n",
        "            -1, # inh FR mean\n",
        "            -1, # inh FR std\n",
        "            -1, # exc P_0 mean (0 to 1)\n",
        "            -1, # exc P_0 std\n",
        "            -1, # inh P_0 mean (0 to 1)\n",
        "            -1, # inh P_0 std\n",
        "#distal trunk\n",
        "            -1, # excitation ('TRUE'/'FALSE')\n",
        "            -1, # inhibition ('TRUE'/'FALSE')\n",
        "            -1, # length\n",
        "            -1, # radius\n",
        "            -1, # exc FR mean\n",
        "            -1, # exc FR std\n",
        "            -1, # inh FR mean\n",
        "            -1, # inh FR std\n",
        "            -1, # exc P_0 mean (0 to 1)\n",
        "            -1, # exc P_0 std\n",
        "            -1, # inh P_0 mean (0 to 1)\n",
        "            -1, # inh P_0 std\n",
        "#basal dendrites\n",
        "            -1, # excitation ('TRUE'/'FALSE')\n",
        "            -1, # inhibition ('TRUE'/'FALSE')\n",
        "            -1, # number of dendrites\n",
        "            -1, # proximal section length\n",
        "            -1, # middle section length\n",
        "            -1, # distal section length\n",
        "            -1, # proximal radius\n",
        "            -1, # middle radius\n",
        "            -1, # distal radius\n",
        "            -1, # angle\n",
        "            -1, # exc FR mean\n",
        "            -1, # exc FR std\n",
        "            -1, # inh FR mean\n",
        "            -1, # inh FR std\n",
        "            -1, # exc P_0 mean (0 to 1)\n",
        "            -1, # exc P_0 std\n",
        "            -1, # inh P_0 mean (0 to 1)\n",
        "            -1, # inh P_0 std\n",
        "#oblique dendrites\n",
        "            -1, # excitation ('TRUE'/'FALSE')\n",
        "            -1, # inhibition ('TRUE'/'FALSE')\n",
        "            -1, # number of dendrites # counted 15 in hay model\n",
        "            -1, # length\n",
        "            -1, # radius\n",
        "            -1, # angle\n",
        "            -1, # exc FR mean\n",
        "            -1, # exc FR std\n",
        "            -1, # inh FR mean\n",
        "            -1, # inh FR std\n",
        "            -1, # exc P_0 mean (0 to 1)\n",
        "            -1, # exc P_0 std\n",
        "            -1, # inh P_0 mean (0 to 1)\n",
        "            -1, # inh P_0 std\n",
        "#tuft dendrites\n",
        "            -1, # excitation ('TRUE'/'FALSE')\n",
        "            -1, # inhibition ('TRUE'/'FALSE')\n",
        "            -1, # number of dendrites\n",
        "            -1, # proximal section length\n",
        "            -1, # middle section length\n",
        "            -1, # distal section length\n",
        "            -1, # proximal radius\n",
        "            -1, # middle radius\n",
        "            -1, # distal radius\n",
        "            -1, # angle\n",
        "            -1, # exc FR mean\n",
        "            -1, # exc FR std\n",
        "            -1, # inh FR mean\n",
        "            -1, # inh FR std\n",
        "            -1, # exc P_0 mean (0 to 1)\n",
        "            -1, # exc P_0 std\n",
        "            -1, # inh P_0 mean (0 to 1)\n",
        "            -1, # inh P_0 std\n",
        "#axon\n",
        "            -1, # length\n",
        "            -1, # radius # hay uses 0.5 #we had at 8\n",
        "#passive basal\n",
        "            -1, # number of dendrites\n",
        "            -1, # length\n",
        "            -1 # radius\n",
        "        ]\n",
        "      \n",
        "      \n",
        "# example of changing biophysical parameters (check \"biophys_entries\" in \"Cell\" class for meaning, bounds can also be found there)\n",
        "#latest conductances from Detailed Model Updated 8/21/22\n",
        "#Ih may be off for apical sections; The detailed model axon shas only g_pas, but we have given the axon some conductances closer to the soma, and may need to change\n",
        "#also setting a conductance to 0.0 may throw some sort of error\n",
        "biophys = [0.0000338,0.0000467,0.0000589,0.0000589,0.0000589,0.0000325,0.0000100, # g_pas of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "                                    2.04/10,0.0213,0.0213,0.0213,0.0213,0.0,0.0, # gNaTa_t of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal # axon was 2.89618\n",
        "                                    0.693,0.000261,0.000261,0.000261,0.000261,0.0,0.0, # gSKv3_1 of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal #axon was 0.473799\n",
        "                                    0.000992,0.0,0.0000555,0.000555,.0000555,0.0,0.0,  # gCA_HVA of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal #basal was 0.000992\n",
        "                                    0.00343,0.0,0.000187,0.0187,0.000187,0.0,0.0, # gCA_LVAst of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "                                    0.0000675,0.0000675,0.0000675,0.0000675,0.0, # gIm of basal, midTrunk, distTrunk, tuft, axon\n",
        "                                    460.0,122,122,122,122,277.300774,122, # decay_CaDynamics of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "                                    0.000501,0.000509,0.000509,0.000509,0.000509,0.000525,0.000509, # gamma_CaDynamics of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "                                    0.0002,0.0002,0.0020077,0.00507257227,0.01535011884,0.0001,0.0002, # gIh of soma, basal, midTrunk, distTrunk, tuft, axon, passiveBasal\n",
        "                                    0.0441,0.0012,0.0012,0.0012,0.0012,0.000047, # gSk_E2 of soma, basal, midTrunk, distTrunk, tuft, axon\n",
        "                                    0.0812,0.077274, # gK_Tst of soma, axon\n",
        "                                    0.00223,0.188851, # gK_Pst of soma, axon\n",
        "                                    0.00172,0.0  # gNap_Et2 of soma, axon\n",
        "                                    ]\n",
        "timestart=time.time()\n",
        "sim = Simulation(geo_standard,elec_pos,loc_param,geo_param=geo_param,biophys=biophys,gmax=0.05,scale=100.,spike_threshold = 10)  # 0.001 -0.012 #gmax=.005, scale=100\n",
        "timestop=time.time()\n",
        "elapseddeftime=timestop-timestart\n",
        "simtime=tstop/1000 #convert from ms to s\n",
        "print('It took',round(elapseddeftime),'sec to define the simulation model.') #need to optomize input grouping # location check takes a long time since it iterates through checking a list of synapse locations for each group/cluster within the section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GfdmtkklD8dR"
      },
      "outputs": [],
      "source": [
        "nseg = len(sim.cells[0].segments)\n",
        "numTstep = int(tstop/dt)\n",
        "\n",
        "\n",
        "seg_list = sim.cells[0].get_seg_by_id(range(nseg))\n",
        "\n",
        "Vrecord = []\n",
        "for i in range(0,len(seg_list)):\n",
        "     Vrecord.append(seg_list[i])\n",
        "\n",
        "dend_v = Recorder(Vrecord)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sZvfttSv5Zk-"
      },
      "outputs": [],
      "source": [
        "sim.run()\n",
        "lfp = sim.get_lfp().T\n",
        "t = sim.t()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CzJhJAX5dOt",
        "outputId": "9d1ce99e-4a3d-49d7-e0e4-147506c2a7e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v_rest: -67.27583177179828\n",
            "v_final: -74.87851022230534\n",
            "v_tau: -72.12634062322178\n",
            "v at tic: -72.13120819227441\n",
            "timeAtV: 163.2\n",
            "timestep where tau occurs: 1632\n",
            "tau: 13.199999999999989 (ms)\n",
            "tau: 0.013199999999999988 (s)\n",
            "Input Resistance(dVdI): 76.02678450507057 MOhms\n"
          ]
        }
      ],
      "source": [
        "from pandas.core.internals.managers import create_block_manager_from_arrays\n",
        "v_dend = dend_v.as_numpy()\n",
        "\n",
        "v_rest = v_dend[0][1000]\n",
        "print('v_rest:',v_rest)\n",
        "v_final = v_dend[0][5000]\n",
        "print('v_final:', v_final)\n",
        "\n",
        "calc = v_rest -((v_rest - v_final) * 0.638)\n",
        "\n",
        "print('v_tau:',calc)\n",
        "\n",
        "\n",
        "i = 150 \n",
        "while v_dend[0][i] > calc:\n",
        "  i = i + 1\n",
        "\n",
        "print('v at tic:',v_dend[0][i])\n",
        "\n",
        "\n",
        "timeAtV = i/10\n",
        "print('timeAtV:', timeAtV)\n",
        "print('timestep where tau occurs:', i)\n",
        "t = timeAtV - 150\n",
        "t_ins = t/1000\n",
        "\n",
        "print('tau:',t,'(ms)')\n",
        "print('tau:',t_ins,'(s)')\n",
        "\n",
        "\n",
        "deltaV = (v_rest - v_final)\n",
        "deltaI = (0 - (-100))\n",
        "dVdI = deltaV / (deltaI /1000)\n",
        "\n",
        "print('Input Resistance(dVdI):',dVdI,'MOhms')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrf8pJE95k-u"
      },
      "source": [
        "1.  V_rest = -72.0 ms\n",
        "2.  Calculation of time constant:\n",
        "*   Start inject: 150ms / -72mV \n",
        "*   Final Value: ~ -75.34mV\n",
        "*   Difference: ((old)-15.34   | 63.2% = 9.78   | -60 – 8.63 )  = \n",
        "-73.89\n",
        "*   Time at – 69.78: 170.375 ms\n",
        "*   τ = 182.225-150 \n",
        "*   τ  = 32.2249 ms\n",
        "*   τ  = .032225 s\n",
        "\n",
        "3.  Input Resistance \n",
        "\n",
        "  ΔV/ΔI = ( -60 – (-92.24) )/( 0 – (-100pA) ) \n",
        "\n",
        "  = 15.34mV / 0.1 nA \n",
        "\n",
        "  R_in   = 182.364 MΩ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "WPJaKlruI0Zm",
        "outputId": "aadcdda6-fad1-4d32-c619-7fdb93429bcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([], <a list of 0 Text major ticklabel objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,4))\n",
        "plt.plot(np.arange(0,((h.tstop)+.1),.1),v_dend[0],color='r')\n",
        "plt.hlines(-65,0,tstop, color = 'grey', linestyle = 'dashed')\n",
        "plt.hlines(-40,0,tstop, color = 'grey', linestyle = 'dashed')\n",
        "plt.hlines(0,0,tstop, color = 'grey', linestyle = 'dashed')\n",
        "plt.vlines(150,50,-100, color = 'grey', linestyle = 'dashed')\n",
        "plt.text(2,3,'0 mV')\n",
        "plt.hlines(-10,50,70)\n",
        "plt.vlines(50,-10,0)\n",
        "plt.text(50,-15,'10 ms')\n",
        "plt.text(2,-5,'10 mV')\n",
        "plt.text(2,-37,'-40 mV')\n",
        "plt.text(2,-62,'-65 mV')\n",
        "plt.title('Soma Voltage')\n",
        "plt.box(False)\n",
        "plt.xticks([])\n",
        "plt.yticks([])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}